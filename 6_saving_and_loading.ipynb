{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6-saving-and-loading.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/deep-learning--from-basics-to-practice/blob/23-keras-part-1/6_saving_and_loading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGhx_pJvU2TG",
        "colab_type": "text"
      },
      "source": [
        "# Saving and Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKoqsBHxU4U9",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dk_OH7sDU523",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "outputId": "5c621084-fde0-4f8f-807c-3fdf2b4b9732"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras import backend as Keras_backend\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from keras import backend as keras_backend\n",
        "keras_backend.set_image_data_format('channels_last')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBywMfkUVFxL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "89b5cc7d-eda8-465c-bbe6-aa4610a26c19"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras import backend as keras_backend\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# load MNIST data and save sizes\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "image_height = X_train.shape[1]\n",
        "image_width = X_train.shape[2]\n",
        "number_of_pixels = image_height * image_width\n",
        "\n",
        "\n",
        "# convert to floating-point\n",
        "X_train = keras_backend.cast_to_floatx(X_train)\n",
        "X_test = keras_backend.cast_to_floatx(X_test)\n",
        "\n",
        "\n",
        "# scale data to range [0, 1]\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "\n",
        "\n",
        "# save the original y_train and y_test\n",
        "original_y_train = y_train\n",
        "original_y_test = y_test\n",
        "\n",
        "# replace label data with one-hot encoded versions\n",
        "number_of_classes = 1 + max(np.append(y_train, y_test)).astype(np.int32)\n",
        "\n",
        "# encode each list into one-hot arrays of the size we just found\n",
        "y_train = to_categorical(y_train, num_classes=number_of_classes)\n",
        "y_test = to_categorical(y_test, num_classes=number_of_classes)\n",
        "\n",
        "# reshape samples to 2D grid, one line per image\n",
        "X_train = X_train.reshape([X_train.shape[0], number_of_pixels])\n",
        "X_test = X_test.reshape([X_test.shape[0], number_of_pixels])\n",
        "\n",
        "def make_one_hidden_layer_model():\n",
        "\n",
        "  # create an empty model\n",
        "  model = Sequential()\n",
        "\n",
        "  # add a fully-connected hidden layer with #nodes = #pixels\n",
        "  model.add(Dense(number_of_pixels, activation='relu', input_shape=[number_of_pixels]))\n",
        "\n",
        "  # add an output layer with softmax activation\n",
        "  model.add(Dense(number_of_classes, activation='softmax'))\n",
        "\n",
        "  # compile the model to turn it from specification to code\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "# make the model\n",
        "one_hidden_layer_model = make_one_hidden_layer_model()  \n",
        "one_hidden_layer_model.summary()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 784)               615440    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                7850      \n",
            "=================================================================\n",
            "Total params: 623,290\n",
            "Trainable params: 623,290\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2p4zx0YwVTyd",
        "colab_type": "text"
      },
      "source": [
        "## Saving Everything in One File"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfV4LiCrVU5b",
        "colab_type": "text"
      },
      "source": [
        "The easiest way to save our model and weights is to call a built-in\n",
        "method belonging to our object that tells it to write itself to a file. The\n",
        "method is, sensibly enough, called save(). When we call this method,\n",
        "the model will write a file that contains both its architecture and\n",
        "weights.\n",
        "\n",
        "The model is saved in a format called HDF5, which conventionally\n",
        "uses the extensions .h5 or .hdf5."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNdnDu4MVS62",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "aaabd3d3-1a56-4361-fb8e-c569f4a7fddb"
      },
      "source": [
        "one_hidden_layer_model.save('One_layer_model.h5')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xgm-Dsw0Vus8",
        "colab_type": "text"
      },
      "source": [
        "Later, we can read this file back in with the load_model() function.\n",
        "Unlike save(), we need to import a new Keras module to access load_\n",
        "model(). That’s because when we load a model, we might not yet have\n",
        "an object whose methods we can call."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4IgZ1SPVxDg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# to load the model and weights\n",
        "model_and_weights = load_model('One_layer_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcAL5_gBWqiG",
        "colab_type": "text"
      },
      "source": [
        "Just like that, the model variable now contains a complete version of\n",
        "the model we saved, with all the weights we’d learned as of the time\n",
        "the file was written."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aT4GGJ0vWrbp",
        "colab_type": "text"
      },
      "source": [
        "## Saving Just the Weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LH9t0DxeWtxY",
        "colab_type": "text"
      },
      "source": [
        "If we only want to save the weights (probably to save a little space on\n",
        "our hard drive), the method save_weights() will do the job."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJUkry35Wizd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "one_hidden_layer_model.save_weights('one_layer_model_weights_only.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxLFAHELXLI5",
        "colab_type": "text"
      },
      "source": [
        "If we want to use these weights later, then we have to first build a\n",
        "model to receive them. The most common case is when our model has\n",
        "the same architecture as the model we used to save the weights. Then\n",
        "the weights just pour right back in to where they had been."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_JRkZ5PXXqs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a model just like the one we saved the weights from\n",
        "model_with_weights_only = make_model()   # a pretend function to make our model\n",
        "\n",
        "# now read the weights back from a file and fill up the model\n",
        "model_with_weights_only.load_weights('one_layer_model_weights_only.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhLDjfEOXyiJ",
        "colab_type": "text"
      },
      "source": [
        "## Saving Just the Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4RggoohXzp1",
        "colab_type": "text"
      },
      "source": [
        "Saving both the model and its weights is the most convenient way to\n",
        "save our work, since we have everything we need in one place. Saving\n",
        "just the weights is useful if we want to share our trained model with\n",
        "people using different libraries that aren’t set up to read the Keras\n",
        "architecture information.\n",
        "\n",
        "If we need to save just the architecture of the model, Keras supports\n",
        "two different formats: JSON and YAML. These\n",
        "formats are both designed to save data structures to text-only files.\n",
        "\n",
        "The technique for saving an architecture in both cases is to use Keras\n",
        "to convert the model into a big character string, and then write that\n",
        "string to a file.\n",
        "\n",
        "To get the architecture back, we read the string from the file, and then\n",
        "use Keras to turn the string into a model.\n",
        "\n",
        "To turn a model into a YAML string, we use the to_yaml() method\n",
        "that is part of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnizxjocYxPr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# How to save just the architecture, without weights, using YAML\n",
        "import yaml\n",
        "\n",
        "filename = 'one_layer_model_architecture_only.h5'\n",
        "yaml_string = model_with_weights_only.to_model()\n",
        "with open(filename, 'w') as outfile:\n",
        "  yaml.dump(yaml_string, outfile)\n",
        "\n",
        "# How to load just the architecture, without weights, using YAML\n",
        "from keras.models import model_from_yaml\n",
        "\n",
        "with open(filename) as yaml_data:\n",
        "    yaml_string = yaml.load(yaml_data)\n",
        "\n",
        "model = model_from_yaml(yaml_string)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0MF5-mSao-C",
        "colab_type": "text"
      },
      "source": [
        "## Using Pre-Trained Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irbNY6p5ap-z",
        "colab_type": "text"
      },
      "source": [
        "Some deep learning models can have dozens of layers, and may have\n",
        "been trained for days or weeks on mountains of data that we don’t\n",
        "have access to. But if the authors of the model have released the structure\n",
        "and weights, then we can instantly use their model and all the\n",
        "hard work that went into it.\n",
        "\n",
        "We often fine-tune these pre-trained models by training them on\n",
        "our own data, helping them specialize on the tasks we need to do. This\n",
        "is sometimes called transfer learning.\n",
        "\n",
        "We might even modify the architecture, such as by adding a few layers\n",
        "of or own to the end of the pre-trained model. We “protect” the existing\n",
        "model by telling Keras not to change their weights during training.\n",
        "We say that such layers are frozen. This means that only our new layers\n",
        "get updated weights as we train.\n",
        "\n",
        "To freeze a layer, we set the layer’s optional parameter trainable to\n",
        "False. We can later “thaw” a frozen layer by setting this parameter to\n",
        "True and compiling it again."
      ]
    }
  ]
}