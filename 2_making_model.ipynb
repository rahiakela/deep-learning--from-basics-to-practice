{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2-making-model.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/deep-learning--from-basics-to-practice/blob/23-keras-part-1/2_making_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONt9_qjJmzvp",
        "colab_type": "text"
      },
      "source": [
        "# Making the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lt9oU6zRsB5b",
        "colab_type": "text"
      },
      "source": [
        "##Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2Hl9CGGsEHa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "8e13ad17-343e-489b-9728-e8121e8299de"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras import backend as Keras_backend\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from keras import backend as keras_backend\n",
        "keras_backend.set_image_data_format('channels_last')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LCJFIeFsLwu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b2df61a4-c3f2-4a18-bffc-d5522afb1931"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras import backend as keras_backend\n",
        "\n",
        "# load MNIST data and save sizes\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "image_height = X_train.shape[1]\n",
        "print(f'image_height = {image_height}')\n",
        "image_width = X_train.shape[2]\n",
        "print(f'image_width = {image_width}')\n",
        "number_of_pixels = image_height * image_width\n",
        "print(f'number_of_pixels = {number_of_pixels}')\n",
        "print()\n",
        "\n",
        "# convert to floating-point\n",
        "X_train = keras_backend.cast_to_floatx(X_train)\n",
        "X_test = keras_backend.cast_to_floatx(X_test)\n",
        "print(f'Before scalling: \\n {X_train[:1]}')\n",
        "print()\n",
        "\n",
        "# scale data to range [0, 1]\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "print(f'After scalling: \\n {X_train[:1]}')\n",
        "print()\n",
        "\n",
        "# save the original y_train and y_test\n",
        "original_y_train = y_train\n",
        "original_y_test = y_test\n",
        "\n",
        "# replace label data with one-hot encoded versions\n",
        "number_of_classes = 1 + max(np.append(y_train, y_test)).astype(np.int32)\n",
        "print(f'number_of_classes: {number_of_classes}')\n",
        "\n",
        "# encode each list into one-hot arrays of the size we just found\n",
        "y_train = to_categorical(y_train, num_classes=number_of_classes)\n",
        "y_test = to_categorical(y_test, num_classes=number_of_classes)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "image_height = 28\n",
            "image_width = 28\n",
            "number_of_pixels = 784\n",
            "\n",
            "Before scalling: \n",
            " [[[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   3.  18.\n",
            "    18.  18. 126. 136. 175.  26. 166. 255. 247. 127.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.   0.   0.  30.  36.  94. 154. 170. 253.\n",
            "   253. 253. 253. 253. 225. 172. 253. 242. 195.  64.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.   0.  49. 238. 253. 253. 253. 253. 253.\n",
            "   253. 253. 253. 251.  93.  82.  82.  56.  39.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.   0.  18. 219. 253. 253. 253. 253. 253.\n",
            "   198. 182. 247. 241.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.   0.   0.  80. 156. 107. 253. 253. 205.\n",
            "    11.   0.  43. 154.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.  14.   1. 154. 253.  90.\n",
            "     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 139. 253. 190.\n",
            "     2.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  11. 190. 253.\n",
            "    70.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  35. 241.\n",
            "   225. 160. 108.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  81.\n",
            "   240. 253. 253. 119.  25.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "    45. 186. 253. 253. 150.  27.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "     0.  16.  93. 252. 253. 187.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "     0.   0.   0. 249. 253. 249.  64.   0.   0.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "    46. 130. 183. 253. 253. 207.   2.   0.   0.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  39. 148.\n",
            "   229. 253. 253. 253. 250. 182.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  24. 114. 221. 253.\n",
            "   253. 253. 253. 201.  78.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.   0.   0.  23.  66. 213. 253. 253. 253.\n",
            "   253. 198.  81.   2.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.  18. 171. 219. 253. 253. 253. 253. 195.\n",
            "    80.   9.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.  55. 172. 226. 253. 253. 253. 253. 244. 133.  11.\n",
            "     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0. 136. 253. 253. 253. 212. 135. 132.  16.   0.   0.\n",
            "     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            "  [  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "     0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]]]\n",
            "\n",
            "After scalling: \n",
            " [[[0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.01176471 0.07058824 0.07058824 0.07058824 0.49411765 0.53333336\n",
            "   0.6862745  0.10196079 0.6509804  1.         0.96862745 0.49803922\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.11764706 0.14117648 0.36862746 0.6039216\n",
            "   0.6666667  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
            "   0.88235295 0.6745098  0.99215686 0.9490196  0.7647059  0.2509804\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.19215687 0.93333334 0.99215686 0.99215686 0.99215686\n",
            "   0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.9843137\n",
            "   0.3647059  0.32156864 0.32156864 0.21960784 0.15294118 0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.07058824 0.85882354 0.99215686 0.99215686 0.99215686\n",
            "   0.99215686 0.99215686 0.7764706  0.7137255  0.96862745 0.94509804\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.3137255  0.6117647  0.41960785 0.99215686\n",
            "   0.99215686 0.8039216  0.04313726 0.         0.16862746 0.6039216\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.05490196 0.00392157 0.6039216\n",
            "   0.99215686 0.3529412  0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.54509807\n",
            "   0.99215686 0.74509805 0.00784314 0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.04313726\n",
            "   0.74509805 0.99215686 0.27450982 0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.13725491 0.94509804 0.88235295 0.627451   0.42352942 0.00392157\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.31764707 0.9411765  0.99215686 0.99215686 0.46666667\n",
            "   0.09803922 0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.1764706  0.7294118  0.99215686 0.99215686\n",
            "   0.5882353  0.10588235 0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.0627451  0.3647059  0.9882353\n",
            "   0.99215686 0.73333335 0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.9764706\n",
            "   0.99215686 0.9764706  0.2509804  0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.18039216 0.50980395 0.7176471  0.99215686\n",
            "   0.99215686 0.8117647  0.00784314 0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.15294118 0.5803922  0.8980392  0.99215686 0.99215686 0.99215686\n",
            "   0.98039216 0.7137255  0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.09411765 0.44705883\n",
            "   0.8666667  0.99215686 0.99215686 0.99215686 0.99215686 0.7882353\n",
            "   0.30588236 0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.09019608 0.25882354 0.8352941  0.99215686\n",
            "   0.99215686 0.99215686 0.99215686 0.7764706  0.31764707 0.00784314\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.07058824 0.67058825 0.85882354 0.99215686 0.99215686 0.99215686\n",
            "   0.99215686 0.7647059  0.3137255  0.03529412 0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.21568628 0.6745098\n",
            "   0.8862745  0.99215686 0.99215686 0.99215686 0.99215686 0.95686275\n",
            "   0.52156866 0.04313726 0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.53333336 0.99215686\n",
            "   0.99215686 0.99215686 0.83137256 0.5294118  0.5176471  0.0627451\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]\n",
            "  [0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.         0.         0.\n",
            "   0.         0.         0.         0.        ]]]\n",
            "\n",
            "number_of_classes: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OtUuy5uoTbU",
        "colab_type": "text"
      },
      "source": [
        "##Motivation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdFvkDm_oeij",
        "colab_type": "text"
      },
      "source": [
        "The beauty of model-making in Keras is that creating the structure of\n",
        "our model (that is, our neural network’s architecture) is streamlined.\n",
        "There are only two steps.\n",
        "\n",
        "First, we name the layers we want in the order we want them. This is\n",
        "called specifying the model.\n",
        "\n",
        "Second, we tell Keras how to use this model to learn. We tell it which\n",
        "loss function and optimizer to use, and what data we’d like it to collect\n",
        "along the way. This is called compiling the model. The compilation\n",
        "step converts our specification into code that runs on the backend\n",
        "we’ve chosen.\n",
        "\n",
        "Our first model for classifying MNIST data will be simple. It will have\n",
        "an input layer (which is implicit in every network), a single hidden\n",
        "layer, and an output layer. The hidden and output layers will both\n",
        "be fully-connected, or dense, layers.\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/simple-deep-learning-model.JPG?raw=1' width='800'/>\n",
        "\n",
        "We’ve decided to set up our first layer to have a single neuron for each\n",
        "pixel. This is a common way to configure the first layer, but it’s definitely\n",
        "not required. We could use 5 neurons or 5000 if we thought that\n",
        "would produce better results.\n",
        "\n",
        "Using this “one neuron per input pixel” approach for our 28 by 28\n",
        "images, our first layer requires 28×28=784 neurons.\n",
        "\n",
        "A full-connected layer can only take\n",
        "in a 1D list. There’s no processing inside of a dense layer would let\n",
        "it figure out how to get at the pixels in a 2D data structure. We’ll see\n",
        "later that convolution layers have that processing, so we can give them\n",
        "grids directly. But right now we’re using a dense layer, and the input to\n",
        "a dense layer is a list.\n",
        "\n",
        "So we need to convert each input sample of 28 by 28 pixels into a 1D\n",
        "list of 784 values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnPegZFqpjux",
        "colab_type": "text"
      },
      "source": [
        "## Turning Grids into Lists"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rr0A2lgvpk6g",
        "colab_type": "text"
      },
      "source": [
        "There are at least two ways to do this. The first is to build it right into\n",
        "our neural network, using the Reshape utility layer provided by Keras.\n",
        "The second is to reshape the data ourselves before training.\n",
        "\n",
        "To convert our images into a list, we’ll convert our starting 3D input\n",
        "data into a 2D grid. Each row of the grid is one sample, made up of a\n",
        "list of 784 features.\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/2-d-rid.JPG?raw=1' width='800'/>\n",
        "\n",
        "There are two ways to use reshape(). Let’s first\n",
        "use the version where we call it from Numpy and pass it the array we’re\n",
        "reshaping as the first argument.\n",
        "\n",
        "The second argument to reshape() is a list with the new dimensions.\n",
        "In this case, the second argument is the list [60000, 748]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J-bfdS5rnkD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshape samples to 2D grid, one line per image\n",
        "X_train = np.reshape(X_train, [X_train.shape[0], number_of_pixels])\n",
        "X_test = np.reshape(X_test, [X_test.shape[0], number_of_pixels])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJPAvkqGsvUX",
        "colab_type": "text"
      },
      "source": [
        "The other way to call reshape() is to call it as a\n",
        "method on the object being reshaped. In this case, the only necessary\n",
        "argument is the list containing the new dimensions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pckfKnkmsuqG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshape samples to 2D grid, one line per image\n",
        "X_train = X_train.reshape([X_train.shape[0], number_of_pixels])\n",
        "X_test = X_test.reshape([X_test.shape[0], number_of_pixels])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "133Wi7-rtLH2",
        "colab_type": "text"
      },
      "source": [
        "Both of these variations produce the same results, so we can use\n",
        "whichever one we prefer. We’ll use the shorter, second version in the\n",
        "following discussion."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3q4FEGGtMD4",
        "colab_type": "text"
      },
      "source": [
        "## Creating the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kdyEw65tOV5",
        "colab_type": "text"
      },
      "source": [
        "We start by telling Keras the overall architecture of our model. Our\n",
        "choices are basically “a list of layers,” and “anything else.”\n",
        "\n",
        "The “list of layers” architecture is called the Sequential model. That’s\n",
        "perfect for us, since our architecture of Figure 23.21 is just two dense\n",
        "layers one after the other. In other words, they can be described as a\n",
        "2-element list starting with the hidden layer and ending with the output\n",
        "layer.\n",
        "\n",
        "The “anything else” architecture is called the Functional model. This\n",
        "is more flexible than the Sequential model, but requires a little more\n",
        "work from us. We’ll come back to the Functional model later.\n",
        "\n",
        "We build a model in the Sequential style using the Sequential API,\n",
        "which is a collection of library calls designed to make this process easy.\n",
        "The beauty of the Sequential API is that to create our model we just name our layers in order from start to finish.\n",
        "\n",
        "The first time we add a layer to our model, Keras will automatically create\n",
        "an input layer for us to hold the incoming data. Then it places our\n",
        "new layer after that. We could stop right there if we wanted, and that\n",
        "would be a 1-layer neural network (remember that we usually don’t\n",
        "count the input layer, since it doesn’t do any processing).\n",
        "\n",
        "But we can keep going, and add as many more layers as we like. Each\n",
        "new layer takes its input from the most recently added layer. The last\n",
        "layer we add in is implicitly our output layer. We never explicitly say\n",
        "that we’re starting or ending. We just add in layers until we’re done."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lw4bgiTttKnx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "0006acdc-27cb-4b10-9c11-fe2fe0e6397c"
      },
      "source": [
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WS9yjAt7uI6-",
        "colab_type": "text"
      },
      "source": [
        "Let’s start building our model. The first layer is always the input layer.\n",
        "But recall that the input layer is implicit. We don’t usually draw it, or\n",
        "count it, and in the Sequential model we usually don’t even explicitly\n",
        "make it.\n",
        "\n",
        "This is fine, because the input layer does nothing but hold the feature\n",
        "list for a sample. So the only thing we need to tell Keras about the input\n",
        "layer is how big that list should be, and it will make the appropriate\n",
        "storage for us.\n",
        "\n",
        "We tell Keras the size of the input layer with an optional argument\n",
        "called input_shape. We pass a value to this argument in the first layer\n",
        "only. In other words, this argument must be included when we make\n",
        "our first layer, but must not be in any others. Every type of layer that\n",
        "can serve as the first layer in a sequence (including the fully-connected\n",
        "layer we’ll be using), takes input_shape as an optional parameter.\n",
        "\n",
        "Keras calls a fully-connected layer a dense layer. Note that here the\n",
        "word “dense” refers to how the layer connects to the layer that precedes\n",
        "it.\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/schematic-view-ense-layer.JPG?raw=1' width='800'/>\n",
        "\n",
        "A schematic view of a Dense layer. The three colored\n",
        "neurons make up the dense layer. Each of them connects to every neuron\n",
        "in the preceding layer (in gray). When we create this layer, we’re only\n",
        "declaring the nature of its connections to the layer before it, and we’re\n",
        "saying nothing about what happens to its outputs.\n",
        "\n",
        "To add a dense layer to our model, we create a Dense object and then\n",
        "append it to the end of our model’s sequence of layers.\n",
        "\n",
        "The necessary first argument is the size of the layer. This is just the\n",
        "number of neurons. This can be, and often is, different from the number\n",
        "of nodes in the preceding layer.\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/fully-connected-layer.JPG?raw=1' width='800'/>\n",
        "\n",
        "Our fully-connected layer is shown with colored neurons,\n",
        "connecting to a previous layer with gray neurons. The number of neurons\n",
        "in the fully-connected layer is independent of the number of neurons in\n",
        "the layer that precedes it.\n",
        "\n",
        "The first optional argument we’ll use tells Keras which activation unit\n",
        "to place after each neuron in the layer. We can specify any one of the\n",
        "functions built into Keras (and, as usual, listed in the documentation)\n",
        "by supplying a string. Common choices are ′relu′ and ′tanh′\n",
        "for the ReLU and tanh functions in hidden layers, and ′softmax′ or\n",
        "′sigmoid′ for the output layer. The default is ′None′, or the linear\n",
        "activation function, so for internal layers we’ll almost always want to\n",
        "specify one of the other choices.\n",
        "\n",
        "The second optional argument we’ll use is input_shape, which defines\n",
        "the size of each dimension in the input. As we saw above, we use this\n",
        "only for the very first layer in a model. The value of this argument is a\n",
        "list that tells Keras to build an input layer of the given shape and size,\n",
        "which must match the shape and size of each sample we’ll be providing.\n",
        "\n",
        "Since each of our samples (after processing) is a 1D list of 784 numbers,\n",
        "we’ll tell Keras that our input_shape is a 1D list of 784 numbers (using\n",
        "the variable number_of_pixels that we saved during pre-processing)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZ48aYt3uHy7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "7f97bb00-3ad2-4268-9acf-a3d15124f25d"
      },
      "source": [
        "from keras.layers import Dense\n",
        "\n",
        "# create the Dense layer\n",
        "dense_layer = Dense(number_of_pixels, activation='relu', input_shape=[number_of_pixels])\n",
        "\n",
        "# append our layer to the list of layers in model\n",
        "model.add(dense_layer)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6XKxtj8wxnO",
        "colab_type": "text"
      },
      "source": [
        "But it’s conventional to create the layer and add it to the model in a\n",
        "single line."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8QLpXTxwTc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Dense(number_of_pixels, activation='relu', input_shape=[number_of_pixels]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckvq-8YexJgG",
        "colab_type": "text"
      },
      "source": [
        "Now we can add the next layer of our model. This will be another Dense\n",
        "layer, but with 10 neurons.\n",
        "\n",
        "We create our next Dense layer much like the previous one, but with\n",
        "a few changes. In particular, we leave out the input_shape argument,\n",
        "since that is only for the very first layer.\n",
        "\n",
        "As always, the first argument, which is un-named and mandatory, is\n",
        "the number of neurons. Since we’re categorizing our images into 10\n",
        "classes, we’ll have 10 neurons, one for each class. We’ll use the variable\n",
        "number_of_classes that we saved during pre-processing.\n",
        "\n",
        "we often use softmax to process the outputs\n",
        "of a final dense layer in a classifier in order to turn them into probabilities.\n",
        "Let’s do that here. We need only name it as a string, and Keras\n",
        "will take care of the rest."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StqDuXB7xAth",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(Dense(number_of_classes, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u96DPSgkxn_z",
        "colab_type": "text"
      },
      "source": [
        "Keep in mind that because this layer is fully-connected to the previous\n",
        "layer, each of these 10 nodes receives inputs from all 784 nodes in the\n",
        "hidden layer.\n",
        "\n",
        "That’s the whole thing. We’ve built a deep-learning model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge-Vppc7xjIo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(number_of_pixels, activation='relu', input_shape=[number_of_pixels]))\n",
        "model.add(Dense(number_of_classes, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRUC75IGyKz-",
        "colab_type": "text"
      },
      "source": [
        "That’s all there is to it! Our model is complete!\n",
        "\n",
        "We can ask Keras to print out the model in text form. This isn’t terribly\n",
        "revealing for our simple example, but it can come in useful for much\n",
        "larger models with tens or hundreds of layers. We call the model’s\n",
        "summary() method.This printout lists the layers\n",
        "in the order they were placed into the network, so we read it top-down."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mb6EhKAyKBg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "7f4237af-48b0-41a2-da03-756d62b9b759"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_5 (Dense)              (None, 784)               615440    \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                7850      \n",
            "=================================================================\n",
            "Total params: 623,290\n",
            "Trainable params: 623,290\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFWzTz_8yl5y",
        "colab_type": "text"
      },
      "source": [
        "The column labeled “Output Shape” tells us the shape of the tensor\n",
        "that comes out of each layer, in the form of a list of dimensions. When\n",
        "we see None as an entry here, this is a placeholder for the number of\n",
        "samples that are provided as a mini-batch during training. \n",
        "\n",
        "For example, if we have a mini-batch size of 64, then the first layer will process 64 of our samples in one shot (using the GPU if it can). The output\n",
        "will be a list containing 64 rows, each with 784 elements. But since\n",
        "right now Keras doesn’t know the size of the mini-batch, it uses None\n",
        "to stand for “Not Yet Known.”\n",
        "\n",
        "The summary also tells us how many parameters, or weights, are used\n",
        "by each layer, and then it adds those up to tell us the total number\n",
        "of parameters in the model. \n",
        "\n",
        "We can see that:-\n",
        "* dense_1, the first Dense layer, has 784 neurons, each of which reads the value of each of the 784\n",
        "inputs. Since each connection has a weight, there are 784×784=614,656\n",
        "weights. Each neuron also has a bias term, so adding the 784 bias terms\n",
        "to the number we just got gives us the 615,440 in the table. That’s a lot\n",
        "of weights! \n",
        "* Similarly, the second layer has 10 neurons, each with a connection\n",
        "to each of the 784 neurons in the previous layer. Remembering\n",
        "to add the 10 bias terms, we get (10×784)+10, or 7,850 parameters.\n",
        "\n",
        "The final line adds these numbers together, telling us that the complete\n",
        "model has over 600,000 parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d15Wq0PzRlL",
        "colab_type": "text"
      },
      "source": [
        "## Compiling the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUBOna_UzSv2",
        "colab_type": "text"
      },
      "source": [
        "So far, our model is nothing more than a list of specifications. It’s a\n",
        "potential model, but it’s no more a real model than blueprints for a\n",
        "house are a real house. That house has to be built from the blueprints.\n",
        "In our case, we need to turn our description into running code. We call\n",
        "this compiling the model. When our model is compiled, it’s ready for\n",
        "training.\n",
        "\n",
        "To compile the model, we need to give Keras at least two pieces of\n",
        "information.\n",
        "* First, we have to tell Keras how to measure the error for each sample\n",
        "(that is, how to put a number to any difference between the network’s\n",
        "output and the target we want it to produce). \n",
        "* Second, we have to tell\n",
        "it which optimizer it should use to update the weights to reduce that\n",
        "error. Let’s look at these in turn.\n",
        "\n",
        "To measure the quality of the weights we need a loss (or cost) function.\n",
        "\n",
        "That function will compare the one-hot label with the outputs from\n",
        "our final layer. This comparison uses the idea of entropy to determine how close our match is. The name of the\n",
        "loss function we want combines these two ideas into the long string\n",
        "′categorical_crossentropy′.\n",
        "\n",
        "If we have just two categories, and we’re using one output to decide\n",
        "between them (perhaps setting it to a value near 0 for one category\n",
        "and a value near 1 for the other), the function that evaluates the error\n",
        "for that case is named ′binary_crossentropy′.\n",
        "\n",
        "Happily, our goal here is basic categorization using multiple outputs,\n",
        "so we can use the pre-built ′categorical_crossentropy′ loss. That\n",
        "tells the network that we want the network’s outputs to match the\n",
        "numbers in our one-hot label as closely as possible.\n",
        "\n",
        "With the loss function selected, our next job is to pick the optimizer.\n",
        "Once the error has been computed, Keras gives it to the optimizer,\n",
        "which uses that error to update the weights. We saw a variety of optimizers\n",
        "in Chapter 19, with names like SGD, RMSprop, and Adagrad.\n",
        "\n",
        "There are many other optional pieces of information we can give to\n",
        "Keras when we compile our model. One of the most common is to provide\n",
        "a list of measurements, called metrics, telling Keras what we’d\n",
        "like it to measure as the model learns. We can think of these metrics as\n",
        "supplemental error or loss functions, but they’re only computed and\n",
        "returned to us as helpful information for understanding and monitoring\n",
        "the learning process, and are not used to update the model.\n",
        "\n",
        "We compile our model by calling our model’s compile() method. This\n",
        "builds everything that the model needs to actually run on our computer\n",
        "with our chosen backend. Because this information is saved\n",
        "along with the model object, we don’t have to save anything ourselves.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_RfWtfmyfyL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "e39e442a-023a-47c0-af6d-faafb30e26bd"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2s0T0JR1Ls6",
        "colab_type": "text"
      },
      "source": [
        "Compiling a model with its compile() method and our\n",
        "arguments. We’re choosing the ′categorical_crossentropy′ loss\n",
        "function and the ′adam′ optimizer. Using these strings is a shorthand\n",
        "for creating the corresponding objects with their defaults. We’re also\n",
        "telling it that we’ll want it to measure and return the ′accuracy′ once\n",
        "we start training.\n",
        "\n",
        "If we think we’re close but things could be better, we might decide to\n",
        "create a custom optimizer and set some of the parameters to something\n",
        "other than the defaults.\n",
        "\n",
        "When we create our optimizer using the string\n",
        "′adam′, we’re asking for an instance of the Adam\n",
        "optimizer with all of its default values. To set some of those values ourselves,\n",
        "we make our own instance of an Adam object where we specify\n",
        "whatever parameters we want to give values to, leaving all the others\n",
        "at their defaults. We then hand that object to compile(), instead of\n",
        "giving it a string."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XV298UeV1htr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import optimizers\n",
        "\n",
        "slow_adam = optimizers.Adam(lr=0.0001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=slow_adam, metrics='accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttW8THEr2BmX",
        "colab_type": "text"
      },
      "source": [
        "The loss functions don’t take parameters, so unless we’re using a custom\n",
        "function that we wrote ourselves, we usually provide a string\n",
        "naming one of the built-in functions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PR1JwXhI2Vak",
        "colab_type": "text"
      },
      "source": [
        "## Model Creation Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wo1A9DKj2Ws9",
        "colab_type": "text"
      },
      "source": [
        "We started out with how to create a new model. We began by creating\n",
        "an empty Sequential object. Then we added a dense, or fully-connected,\n",
        "hidden layer that also specified the shape of the input layer.\n",
        "We finished with another dense layer that produced 10 outputs, one\n",
        "for each category."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGNog0GC2ibP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "def make_one_hidden_layer_model():\n",
        "\n",
        "  # create an empty model\n",
        "  model = Sequential()\n",
        "\n",
        "  # add a fully-connected hidden layer with #nodes = #pixels\n",
        "  model.add(Dense(number_of_pixels, activation='relu', input_shape=[number_of_pixels]))\n",
        "\n",
        "  # add an output layer with softmax activation\n",
        "  model.add(Dense(number_of_classes, activation='softmax'))\n",
        "\n",
        "  # compile the model to turn it from specification to code\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "# make the model\n",
        "model = make_one_hidden_layer_model()  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40tafbbc3oQ_",
        "colab_type": "text"
      },
      "source": [
        "Building our model took only three lines of code. Compiling it took\n",
        "only one. And now we’ll see that training the system also takes only one\n",
        "line. But as we’ve seen, each of these lines packs in a lot of information.\n",
        "\n",
        "Now we’re ready to hand our prepared data to our compiled model\n",
        "and start learning."
      ]
    }
  ]
}