{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4-model-prediction.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/deep-learning--from-basics-to-practice/blob/23-keras-part-1/4_model_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VL6t-aFXY-ln",
        "colab_type": "text"
      },
      "source": [
        "# Model Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYI6kCraZFZi",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdDfW1qhZEYx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "0c0223ad-a969-4246-c781-8576493796b2"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras import backend as Keras_backend\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from keras import backend as keras_backend\n",
        "keras_backend.set_image_data_format('channels_last')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEYXWo2KZVJE",
        "colab_type": "text"
      },
      "source": [
        "## Training A Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTzH5yKzll-K",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iH-O5-O1ZWyK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d6b3aa8d-ab7b-4a43-d040-d6afc39ec2e9"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras import backend as keras_backend\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# load MNIST data and save sizes\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "image_height = X_train.shape[1]\n",
        "image_width = X_train.shape[2]\n",
        "number_of_pixels = image_height * image_width\n",
        "\n",
        "\n",
        "# convert to floating-point\n",
        "X_train = keras_backend.cast_to_floatx(X_train)\n",
        "X_test = keras_backend.cast_to_floatx(X_test)\n",
        "\n",
        "\n",
        "# scale data to range [0, 1]\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "\n",
        "\n",
        "# save the original y_train and y_test\n",
        "original_y_train = y_train\n",
        "original_y_test = y_test\n",
        "\n",
        "# replace label data with one-hot encoded versions\n",
        "number_of_classes = 1 + max(np.append(y_train, y_test)).astype(np.int32)\n",
        "\n",
        "# encode each list into one-hot arrays of the size we just found\n",
        "y_train = to_categorical(y_train, num_classes=number_of_classes)\n",
        "y_test = to_categorical(y_test, num_classes=number_of_classes)\n",
        "\n",
        "# reshape samples to 2D grid, one line per image\n",
        "X_train = X_train.reshape([X_train.shape[0], number_of_pixels])\n",
        "X_test = X_test.reshape([X_test.shape[0], number_of_pixels])\n",
        "\n",
        "def make_one_hidden_layer_model():\n",
        "\n",
        "  # create an empty model\n",
        "  model = Sequential()\n",
        "\n",
        "  # add a fully-connected hidden layer with #nodes = #pixels\n",
        "  model.add(Dense(number_of_pixels, activation='relu', input_shape=[number_of_pixels]))\n",
        "\n",
        "  # add an output layer with softmax activation\n",
        "  model.add(Dense(number_of_classes, activation='softmax'))\n",
        "\n",
        "  # compile the model to turn it from specification to code\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "# make the model\n",
        "one_hidden_layer_model = make_one_hidden_layer_model()  \n",
        "one_hidden_layer_model.summary()\n",
        "\n",
        "# call fit() to train the model, and save the history\n",
        "one_hidden_layer_history = one_hidden_layer_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=256, verbose=2)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 784)               615440    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                7850      \n",
            "=================================================================\n",
            "Total params: 623,290\n",
            "Trainable params: 623,290\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            " - 6s - loss: 0.3060 - acc: 0.9139 - val_loss: 0.1498 - val_acc: 0.9564\n",
            "Epoch 2/20\n",
            " - 6s - loss: 0.1237 - acc: 0.9639 - val_loss: 0.1072 - val_acc: 0.9698\n",
            "Epoch 3/20\n",
            " - 6s - loss: 0.0803 - acc: 0.9771 - val_loss: 0.0806 - val_acc: 0.9762\n",
            "Epoch 4/20\n",
            " - 6s - loss: 0.0572 - acc: 0.9830 - val_loss: 0.0859 - val_acc: 0.9728\n",
            "Epoch 5/20\n",
            " - 6s - loss: 0.0420 - acc: 0.9882 - val_loss: 0.0679 - val_acc: 0.9776\n",
            "Epoch 6/20\n",
            " - 5s - loss: 0.0310 - acc: 0.9916 - val_loss: 0.0614 - val_acc: 0.9806\n",
            "Epoch 7/20\n",
            " - 5s - loss: 0.0240 - acc: 0.9938 - val_loss: 0.0662 - val_acc: 0.9798\n",
            "Epoch 8/20\n",
            " - 5s - loss: 0.0177 - acc: 0.9960 - val_loss: 0.0600 - val_acc: 0.9821\n",
            "Epoch 9/20\n",
            " - 6s - loss: 0.0136 - acc: 0.9970 - val_loss: 0.0599 - val_acc: 0.9818\n",
            "Epoch 10/20\n",
            " - 6s - loss: 0.0096 - acc: 0.9984 - val_loss: 0.0555 - val_acc: 0.9820\n",
            "Epoch 11/20\n",
            " - 6s - loss: 0.0084 - acc: 0.9986 - val_loss: 0.0663 - val_acc: 0.9807\n",
            "Epoch 12/20\n",
            " - 6s - loss: 0.0060 - acc: 0.9993 - val_loss: 0.0579 - val_acc: 0.9841\n",
            "Epoch 13/20\n",
            " - 6s - loss: 0.0063 - acc: 0.9989 - val_loss: 0.0612 - val_acc: 0.9804\n",
            "Epoch 14/20\n",
            " - 6s - loss: 0.0038 - acc: 0.9996 - val_loss: 0.0579 - val_acc: 0.9831\n",
            "Epoch 15/20\n",
            " - 6s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0596 - val_acc: 0.9834\n",
            "Epoch 16/20\n",
            " - 6s - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0576 - val_acc: 0.9831\n",
            "Epoch 17/20\n",
            " - 6s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0578 - val_acc: 0.9833\n",
            "Epoch 18/20\n",
            " - 6s - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0594 - val_acc: 0.9835\n",
            "Epoch 19/20\n",
            " - 6s - loss: 8.8467e-04 - acc: 1.0000 - val_loss: 0.0586 - val_acc: 0.9838\n",
            "Epoch 20/20\n",
            " - 5s - loss: 7.5113e-04 - acc: 1.0000 - val_loss: 0.0596 - val_acc: 0.9832\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLe3GcnZaEGz",
        "colab_type": "text"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ep7617khaFF0",
        "colab_type": "text"
      },
      "source": [
        "Let’s take the model we just trained, and deploy it. We’ll give it some\n",
        "new images that it’s never seen before, and see how it does.\n",
        "\n",
        "We have a sign in a coffee-shop window, some spraypainted\n",
        "marks on the ground near a construction site, a number\n",
        "painted onto the side of a dumpster, and a parking-lot stall number.\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/model-prediction-1.JPG?raw=1' width='800'/>\n",
        "\n",
        "The stenciled numbers in the parking lot stall are not hand-drawn,\n",
        "and they have gaps, so they’re really not appropriate for our system.\n",
        "They’re included just for fun, and to see what our deep-learning system\n",
        "comes up with.\n",
        "\n",
        "When we extract these digits, rotate them to be upright, and prepare\n",
        "them in the same way as the original MNIST data.\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/model-prediction-2.JPG?raw=1' width='800'/>\n",
        "\n",
        "Just to clarify which set we’re working with, let’s make four test sets,\n",
        "one for each group of images. For instance, we’ll arrange the coffee\n",
        "shop data into a grid that has 4 rows and 784 columns.\n",
        "\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/model-prediction-3.JPG?raw=1' width='800'/>\n",
        "\n",
        "The construction data has 7 rows, the dumpster data has 4 rows, and\n",
        "the parking lot data has 3 rows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA9irVSLkr3J",
        "colab_type": "text"
      },
      "source": [
        "### New test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a1DjKQEdniH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# My Seattle photos. Because I didn't want to depend on having other\n",
        "# files around to read in (though in retrospect, I think that would\n",
        "# be okay), I saved the data explicitly as integer arrays. What the\n",
        "# heck, I've left them in here in that form. It does reduce outside\n",
        "# dependencies, but it seems a silly choice to me now. Anyway, there's\n",
        "# nothing interesting here, just intensities of the pixels in grayscale\n",
        "# images. Intensities are in the range [0,255] and images are saved\n",
        "# as a list of 748 elements (so we don't have to reshape them).\n",
        "#\n",
        "\n",
        "Coffeeshop_4 = np.array((\n",
        "26, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 26, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 34, 166, 112, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 2, 168, 172, 5, 176, 255, 255, 22, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 68, 255, 255, 54, 162, 255, 255, 63, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 149, 255, 255, 65, 120, 255, 255, 74, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 2, 243, 255, 255, 12, 89, 255, 255, 95, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 157, 255, 255, 238, 0, 88, 255, 255, 113, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 100, 255, 255, 255, 85, 0, 83, 255, 255, 108, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 71, 252, 255, 253, 142, 0, 0, 58, 255, 255, 133, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 3, 82, 255, 255, 255, 234, 3, 0, 0, 37, 255, 255, 109, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 44, 255, 255, 255, 255, 250, 185, 131, 85, 155, 255, 255, 193, 40, 49, 8, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 11, 206, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 182, 3, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 69, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 83, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 46, 105, 99, 113, 153, 151, 185, 249, 255, 255, 248, 80, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 191, 255, 255, 90, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 161, 255, 255, 72, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 136, 255, 255, 116, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 127, 255, 255, 120, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 75, 255, 255, 166, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 41, 255, 255, 195, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 30, 255, 255, 205, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 221, 255, 146, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 56, 161, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "26, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 11, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 26, \n",
        "))\n",
        "Coffeeshop_5 = np.array((\n",
        "26, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 26, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 15, 34, 29, 36, 29, 30, 27, 82, 159, 82, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 117, 213, 224, 238, 252, 249, 255, 250, 251, 250, 255, 255, 255, 37, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 68, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 122, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 73, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 82, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 48, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 198, 4, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 1, 0, 64, 255, 255, 255, 202, 141, 107, 90, 103, 115, 133, 138, 63, 3, 0, 1, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 1, 0, 100, 255, 255, 255, 100, 2, 26, 71, 98, 76, 5, 0, 0, 1, 2, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 179, 255, 255, 255, 232, 222, 255, 255, 255, 255, 228, 44, 0, 1, 1, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 2, 224, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 245, 22, 0, 2, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 13, 246, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 196, 3, 1, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 60, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 40, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 1, 170, 255, 255, 255, 255, 255, 255, 255, 255, 178, 137, 250, 255, 255, 124, 2, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 1, 196, 255, 255, 255, 255, 204, 131, 204, 129, 7, 0, 159, 255, 255, 193, 9, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 65, 255, 255, 255, 196, 16, 0, 5, 0, 0, 0, 101, 255, 255, 170, 9, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 119, 253, 182, 0, 0, 0, 0, 0, 1, 0, 111, 255, 255, 178, 1, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 1, 0, 0, 60, 34, 0, 0, 0, 1, 1, 0, 15, 222, 255, 255, 149, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 2, 163, 235, 164, 0, 0, 0, 0, 40, 217, 255, 255, 255, 46, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 1, 206, 255, 255, 166, 17, 70, 154, 247, 255, 255, 255, 197, 1, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 150, 255, 255, 255, 240, 255, 255, 255, 255, 255, 229, 31, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 72, 255, 255, 255, 255, 255, 255, 255, 255, 220, 17, 0, 1, 1, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 120, 255, 255, 255, 255, 255, 255, 226, 29, 0, 0, 1, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 1, 181, 255, 255, 255, 228, 143, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 90, 106, 76, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "26, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 26, \n",
        "))\n",
        "Coffeeshop_6 = np.array((\n",
        "26, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 26, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "13, 0, 0, 0, 0, 0, 2, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 2, 2, 0, 0, 4, 6, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 2, 6, 57, 31, 9, 0, 7, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 41, 247, 224, 118, 12, 1, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 2, 98, 255, 255, 255, 130, 9, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 5, 154, 255, 255, 255, 253, 24, 2, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 14, 238, 255, 255, 255, 226, 21, 2, 2, 3, 0, 1, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 13, 160, 255, 255, 255, 229, 24, 0, 1, 2, 16, 10, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 4, 58, 255, 255, 255, 237, 35, 0, 0, 31, 140, 150, 65, 18, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 3, 65, 255, 255, 255, 226, 28, 0, 19, 200, 255, 255, 255, 156, 21, 0, 1, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 4, 74, 255, 255, 255, 247, 48, 5, 95, 255, 255, 255, 255, 255, 171, 20, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 3, 82, 255, 255, 255, 253, 70, 13, 139, 255, 255, 255, 255, 255, 255, 164, 8, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 50, 255, 255, 255, 255, 100, 24, 168, 255, 255, 255, 247, 255, 255, 255, 142, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 16, 175, 255, 255, 255, 93, 49, 255, 255, 255, 255, 96, 81, 254, 255, 255, 84, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 9, 109, 255, 255, 255, 147, 55, 244, 255, 255, 254, 39, 18, 189, 255, 255, 188, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 2, 71, 255, 255, 255, 180, 45, 210, 255, 255, 248, 37, 7, 122, 255, 255, 200, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 20, 199, 255, 255, 178, 54, 190, 255, 255, 199, 17, 26, 148, 255, 255, 201, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 18, 167, 255, 255, 229, 65, 163, 255, 255, 192, 48, 116, 244, 255, 255, 211, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 7, 103, 255, 255, 255, 167, 203, 255, 255, 253, 221, 255, 255, 255, 255, 123, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 2, 38, 223, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 181, 13, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 4, 10, 113, 255, 255, 255, 255, 255, 255, 255, 255, 255, 252, 150, 20, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 3, 0, 17, 157, 249, 255, 255, 255, 255, 243, 193, 142, 61, 15, 0, 2, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 2, 4, 0, 17, 53, 69, 81, 72, 70, 46, 23, 10, 0, 0, 4, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 4, 5, 1, 2, 6, 6, 6, 3, 1, 0, 2, 4, 2, 0, 0, 0, 0, 0, 0, 13, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "26, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 16, 15, 15, 14, 14, 13, 13, 13, 13, 13, 13, 13, 13, 26, \n",
        "))\n",
        "Coffeeshop_8 = np.array((\n",
        "26, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 26, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "13, 0, 0, 0, 0, 0, 0, 2, 4, 6, 12, 9, 4, 5, 5, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 3, 6, 3, 17, 201, 197, 30, 5, 8, 6, 6, 8, 5, 1, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 6, 4, 25, 204, 255, 255, 230, 122, 65, 9, 4, 7, 8, 6, 1, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 4, 35, 226, 255, 255, 255, 255, 255, 255, 214, 87, 6, 5, 9, 3, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 5, 152, 255, 255, 255, 255, 255, 255, 255, 255, 255, 142, 8, 8, 2, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 9, 206, 255, 255, 255, 193, 239, 250, 225, 255, 255, 255, 115, 7, 1, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 6, 213, 255, 255, 183, 15, 36, 46, 15, 180, 255, 255, 191, 9, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 5, 180, 255, 255, 82, 0, 0, 4, 24, 192, 255, 255, 236, 12, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 5, 154, 255, 255, 204, 119, 124, 148, 237, 255, 255, 255, 97, 8, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 5, 44, 252, 255, 255, 255, 255, 255, 255, 255, 255, 95, 13, 6, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 6, 10, 137, 255, 255, 255, 255, 255, 255, 255, 255, 97, 5, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 7, 12, 114, 255, 255, 255, 255, 255, 255, 255, 255, 255, 202, 117, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 5, 12, 218, 255, 255, 255, 211, 93, 76, 152, 255, 255, 255, 255, 123, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 3, 13, 223, 255, 255, 226, 18, 0, 2, 5, 84, 255, 255, 255, 245, 8, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 3, 16, 193, 255, 255, 130, 6, 8, 6, 7, 4, 86, 254, 255, 255, 90, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 3, 11, 196, 255, 255, 48, 5, 8, 7, 6, 1, 18, 253, 255, 255, 102, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 2, 6, 183, 255, 255, 110, 4, 4, 6, 11, 73, 215, 255, 255, 255, 64, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 3, 4, 59, 255, 255, 255, 155, 107, 142, 195, 255, 255, 255, 255, 116, 5, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 4, 5, 3, 173, 255, 255, 255, 255, 255, 255, 255, 255, 255, 115, 3, 2, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 3, 7, 3, 8, 184, 255, 255, 255, 255, 255, 250, 182, 51, 2, 6, 4, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 1, 5, 7, 3, 5, 97, 163, 185, 171, 123, 44, 6, 3, 7, 7, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 2, 6, 8, 4, 3, 7, 10, 9, 7, 5, 6, 8, 8, 2, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 2, 3, 3, 2, 2, 3, 4, 4, 5, 5, 1, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "26, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 26, \n",
        "))\n",
        "\n",
        "\n",
        "\n",
        "Construction_0 = np.array((\n",
        "13, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 19, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 110, 236, 240, 42, 0, 11, 72, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 123, 255, 255, 255, 251, 99, 210, 255, 248, 122, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 10, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 51, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 78, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 194, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 164, 255, 255, 255, 255, 155, 104, 255, 255, 255, 255, 255, 55, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 62, 255, 255, 255, 255, 121, 0, 0, 79, 255, 255, 255, 255, 104, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 91, 255, 255, 255, 212, 0, 0, 0, 0, 229, 255, 255, 255, 142, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 2, 204, 255, 255, 255, 58, 0, 0, 0, 0, 122, 255, 255, 255, 175, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 12, 255, 255, 255, 221, 0, 0, 0, 0, 0, 42, 255, 255, 255, 177, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 15, 244, 255, 255, 194, 0, 0, 0, 0, 0, 0, 160, 255, 255, 238, 18, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 8, 240, 255, 255, 185, 0, 0, 0, 0, 0, 0, 154, 255, 255, 255, 96, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 2, 241, 255, 255, 60, 0, 0, 0, 0, 0, 6, 239, 255, 255, 255, 129, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 72, 254, 255, 255, 67, 0, 0, 0, 0, 0, 32, 255, 255, 255, 255, 61, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 108, 255, 255, 251, 47, 0, 0, 0, 0, 0, 147, 255, 255, 255, 229, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 23, 252, 255, 251, 90, 0, 0, 0, 0, 122, 255, 255, 255, 255, 139, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 207, 255, 255, 255, 104, 23, 37, 139, 255, 255, 255, 255, 255, 8, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 154, 255, 255, 255, 255, 254, 255, 255, 255, 255, 255, 255, 175, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 42, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 188, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 116, 255, 215, 235, 255, 255, 255, 255, 211, 138, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 110, 1, 54, 255, 255, 236, 85, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 77, 77, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "))\n",
        "Construction_2 = np.array((\n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, 57, 86, 110, 114, 58, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 19, 142, 234, 255, 255, 255, 255, 255, 205, 63, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 113, 240, 255, 255, 255, 255, 255, 255, 255, 255, 255, 127, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 6, 179, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 46, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 80, 216, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 212, 25, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 21, 249, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 252, 20, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 1, 195, 255, 255, 255, 255, 255, 255, 190, 88, 62, 101, 220, 255, 255, 255, 255, 249, 22, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 67, 255, 255, 255, 255, 255, 255, 160, 0, 0, 0, 0, 64, 255, 255, 255, 255, 255, 33, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 116, 255, 255, 255, 255, 255, 194, 0, 0, 0, 0, 0, 42, 255, 255, 255, 255, 228, 11, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 46, 252, 255, 255, 255, 255, 33, 0, 0, 0, 0, 3, 89, 255, 255, 255, 255, 118, 4, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 140, 255, 255, 255, 218, 0, 0, 0, 0, 0, 17, 217, 255, 255, 255, 244, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 2, 149, 234, 255, 87, 0, 0, 0, 0, 55, 216, 255, 255, 255, 255, 126, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 6, 42, 0, 0, 0, 0, 50, 255, 255, 255, 255, 255, 216, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 81, 251, 255, 255, 255, 255, 255, 38, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 232, 255, 255, 255, 255, 255, 109, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 220, 255, 254, 255, 255, 255, 132, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 64, 255, 255, 255, 255, 247, 99, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 186, 255, 255, 255, 255, 215, 2, 12, 15, 5, 49, 96, 166, 166, 221, 212, 92, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 22, 255, 255, 255, 255, 255, 219, 132, 160, 206, 233, 255, 255, 255, 255, 255, 255, 255, 129, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 41, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 164, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 2, 237, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 178, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 72, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 199, 74, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 83, 232, 255, 255, 255, 255, 255, 250, 225, 188, 170, 114, 64, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 30, 54, 56, 33, 33, 19, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "))\n",
        "Construction_3 = np.array((\n",
        "26, 0, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 0, 22, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 30, 88, 57, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 63, 203, 255, 255, 255, 173, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "13, 0, 0, 0, 0, 0, 45, 125, 87, 97, 192, 255, 255, 255, 255, 255, 255, 154, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "13, 0, 0, 0, 0, 7, 226, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 49, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "13, 0, 0, 0, 20, 214, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 105, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "13, 0, 0, 0, 94, 255, 255, 255, 255, 255, 255, 247, 136, 41, 172, 255, 255, 255, 183, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "13, 0, 0, 0, 124, 255, 255, 255, 255, 255, 169, 8, 0, 0, 71, 255, 255, 255, 211, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "13, 0, 0, 0, 49, 255, 255, 255, 255, 79, 0, 0, 0, 0, 100, 255, 255, 255, 152, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "13, 0, 0, 0, 0, 31, 130, 153, 50, 0, 0, 0, 0, 0, 180, 255, 255, 255, 53, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 78, 137, 230, 255, 255, 215, 39, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 170, 255, 255, 255, 255, 255, 192, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 164, 255, 255, 255, 255, 255, 255, 218, 66, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 117, 255, 255, 255, 255, 255, 255, 255, 255, 236, 114, 7, 0, 0, 0, 0, 0, 0, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 36, 227, 255, 255, 255, 255, 255, 255, 255, 255, 255, 201, 0, 0, 0, 0, 0, 0, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 70, 107, 110, 106, 133, 182, 253, 255, 255, 255, 110, 0, 0, 0, 0, 0, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 40, 233, 255, 255, 195, 0, 0, 0, 0, 0, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 153, 255, 255, 241, 16, 0, 0, 0, 0, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 201, 255, 255, 252, 26, 0, 0, 0, 0, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 25, 251, 255, 255, 182, 0, 0, 0, 0, 0, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 82, 255, 255, 255, 98, 0, 0, 0, 0, 0, \n",
        "13, 0, 0, 0, 0, 0, 0, 15, 94, 175, 217, 56, 0, 0, 0, 0, 5, 116, 248, 255, 255, 255, 62, 0, 0, 0, 0, 0, \n",
        "13, 0, 0, 0, 0, 0, 0, 103, 255, 255, 255, 247, 180, 161, 175, 210, 248, 255, 255, 255, 255, 191, 0, 0, 0, 0, 0, 0, \n",
        "13, 0, 0, 0, 0, 0, 0, 13, 235, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 238, 28, 0, 0, 0, 0, 0, 0, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 159, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 190, 14, 0, 0, 0, 0, 0, 0, 0, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 161, 255, 255, 255, 255, 255, 255, 252, 167, 64, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 58, 138, 163, 159, 133, 88, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "23, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "))\n",
        "Construction_4 = np.array((\n",
        "13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 0, 26, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 62, 242, 195, 28, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 164, 255, 255, 141, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 4, 0, 0, 0, 0, 0, 198, 255, 255, 147, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 134, 255, 118, 0, 0, 0, 0, 0, 183, 255, 255, 121, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "0, 0, 0, 0, 0, 0, 0, 92, 255, 255, 153, 0, 0, 0, 0, 0, 171, 255, 255, 54, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "0, 0, 0, 0, 0, 0, 0, 198, 255, 255, 148, 0, 0, 0, 0, 0, 202, 255, 248, 21, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "0, 0, 0, 0, 0, 0, 5, 230, 255, 255, 86, 0, 0, 0, 0, 0, 219, 255, 224, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "0, 0, 0, 0, 0, 0, 46, 255, 255, 249, 26, 0, 0, 0, 0, 18, 244, 255, 181, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "0, 0, 0, 0, 0, 0, 85, 255, 255, 191, 0, 0, 0, 0, 0, 27, 252, 255, 133, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "0, 0, 0, 0, 0, 0, 120, 255, 255, 177, 0, 0, 0, 0, 0, 99, 255, 255, 117, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "0, 0, 0, 0, 0, 0, 129, 255, 255, 250, 105, 37, 60, 98, 212, 255, 255, 255, 72, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "0, 0, 0, 0, 0, 0, 121, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 252, 27, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "0, 0, 0, 0, 0, 0, 73, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 43, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "0, 0, 0, 0, 0, 0, 0, 58, 209, 255, 255, 255, 255, 253, 151, 207, 255, 255, 57, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 26, 54, 70, 65, 15, 0, 172, 255, 255, 32, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 156, 255, 223, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 166, 255, 200, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 209, 255, 204, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 215, 255, 230, 4, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 17, 243, 255, 215, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 30, 254, 255, 234, 12, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 57, 255, 255, 255, 152, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 83, 255, 255, 255, 241, 14, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 33, 224, 255, 255, 205, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 19, 184, 227, 46, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 0, 26, \n",
        "))\n",
        "Construction_5 = np.array((\n",
        "25, 12, 12, 2, 7, 14, 4, 7, 14, 0, 8, 11, 5, 9, 24, 23, 16, 0, 14, 18, 22, 14, 9, 3, 10, 6, 8, 21, \n",
        "4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "21, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 17, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, \n",
        "27, 0, 0, 0, 0, 0, 0, 0, 0, 62, 108, 50, 61, 115, 185, 217, 249, 255, 183, 12, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "12, 0, 0, 0, 0, 0, 17, 132, 203, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 166, 0, 0, 0, 0, 0, 0, 0, 5, \n",
        "0, 0, 0, 0, 0, 0, 134, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 248, 12, 0, 0, 0, 0, 0, 0, 6, \n",
        "13, 0, 0, 0, 0, 0, 190, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 43, 0, 0, 0, 0, 0, 0, 2, \n",
        "20, 0, 0, 0, 0, 0, 174, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 184, 4, 0, 0, 0, 0, 0, 0, 5, \n",
        "6, 0, 0, 0, 0, 0, 93, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 208, 107, 0, 0, 0, 0, 0, 0, 0, 0, 5, \n",
        "2, 0, 0, 0, 0, 0, 43, 255, 255, 255, 255, 255, 255, 125, 36, 59, 40, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, \n",
        "10, 0, 0, 0, 0, 0, 82, 255, 255, 255, 255, 255, 255, 101, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, \n",
        "5, 0, 0, 0, 0, 12, 221, 255, 255, 255, 255, 255, 255, 255, 220, 93, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9, \n",
        "11, 0, 0, 0, 0, 86, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 126, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20, \n",
        "22, 0, 0, 0, 0, 46, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 194, 3, 0, 0, 0, 0, 0, 0, 0, 0, 19, \n",
        "16, 0, 0, 0, 0, 0, 118, 255, 255, 255, 220, 189, 213, 255, 255, 255, 255, 255, 210, 0, 0, 0, 0, 0, 0, 0, 0, 24, \n",
        "6, 0, 0, 0, 0, 0, 0, 71, 63, 43, 0, 0, 0, 30, 203, 255, 255, 255, 255, 172, 0, 0, 0, 0, 0, 0, 0, 6, \n",
        "9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 21, 255, 255, 255, 255, 255, 166, 0, 0, 0, 0, 0, 0, 13, \n",
        "14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 119, 255, 255, 255, 255, 255, 15, 0, 0, 0, 0, 0, 16, \n",
        "19, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 254, 255, 255, 255, 255, 78, 0, 0, 0, 0, 0, 21, \n",
        "23, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20, 254, 255, 255, 255, 255, 161, 0, 0, 0, 0, 0, 21, \n",
        "16, 0, 0, 0, 0, 0, 0, 0, 41, 71, 74, 32, 0, 0, 7, 156, 255, 255, 255, 255, 255, 106, 0, 0, 0, 0, 0, 13, \n",
        "9, 0, 0, 0, 0, 0, 35, 209, 255, 255, 255, 255, 120, 138, 236, 255, 255, 255, 255, 255, 255, 5, 0, 0, 0, 0, 0, 12, \n",
        "23, 0, 0, 0, 0, 21, 236, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 98, 0, 0, 0, 0, 0, 0, 5, \n",
        "8, 0, 0, 0, 0, 51, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 133, 0, 0, 0, 0, 0, 0, 0, 6, \n",
        "0, 0, 0, 0, 0, 0, 193, 255, 255, 255, 255, 255, 255, 255, 253, 223, 209, 151, 44, 0, 0, 0, 0, 0, 0, 0, 0, 8, \n",
        "6, 0, 0, 0, 0, 0, 15, 188, 190, 180, 176, 144, 110, 74, 22, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "9, 4, 7, 6, 3, 4, 0, 1, 0, 0, 4, 5, 0, 3, 4, 2, 0, 5, 9, 1, 3, 4, 0, 0, 9, 4, 0, 7, \n",
        "))\n",
        "Construction_7 = np.array((\n",
        "24, 0, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 0, 19, \n",
        "12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "12, 0, 0, 0, 0, 3, 27, 37, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, \n",
        "12, 0, 0, 0, 53, 244, 255, 255, 254, 73, 0, 0, 0, 0, 15, 49, 76, 125, 74, 193, 240, 30, 0, 0, 0, 0, 0, 0, \n",
        "12, 0, 0, 0, 121, 255, 255, 255, 255, 246, 140, 90, 80, 144, 245, 255, 255, 255, 255, 255, 255, 194, 0, 0, 0, 0, 0, 0, \n",
        "12, 0, 0, 0, 77, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 153, 0, 0, 0, 0, 0, \n",
        "12, 0, 0, 0, 39, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 165, 0, 0, 0, 0, 0, \n",
        "12, 0, 0, 0, 17, 243, 255, 255, 255, 255, 255, 224, 210, 217, 230, 226, 183, 188, 255, 255, 255, 255, 142, 0, 0, 0, 0, 0, \n",
        "12, 0, 0, 0, 0, 70, 149, 142, 128, 108, 45, 0, 0, 0, 2, 1, 0, 0, 153, 255, 255, 255, 61, 0, 0, 0, 0, 0, \n",
        "12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 166, 255, 255, 177, 0, 0, 0, 0, 0, 0, \n",
        "12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 50, 255, 255, 255, 100, 0, 0, 0, 0, 0, 0, \n",
        "12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 157, 255, 255, 207, 0, 0, 0, 0, 0, 0, 0, \n",
        "12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 15, 107, 28, 90, 255, 255, 255, 117, 0, 0, 0, 0, 0, 0, 0, \n",
        "12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 26, 232, 255, 253, 254, 255, 255, 131, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 72, 238, 255, 255, 255, 255, 255, 255, 139, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 197, 255, 255, 255, 255, 255, 255, 255, 172, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 114, 255, 255, 255, 255, 255, 255, 133, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 18, 167, 255, 255, 255, 245, 23, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 81, 255, 255, 255, 138, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 145, 255, 255, 242, 24, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 97, 255, 255, 255, 97, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 134, 255, 255, 255, 192, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 225, 255, 255, 255, 49, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 31, 255, 255, 255, 161, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 203, 255, 243, 35, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 50, 128, 22, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "27, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "))\n",
        "Construction_9 = np.array((\n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 59, 215, 212, 202, 192, 149, 99, 31, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20, 131, 255, 255, 255, 255, 255, 255, 255, 253, 59, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 124, 248, 255, 255, 255, 255, 255, 255, 255, 255, 255, 165, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 20, 197, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 104, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 16, 236, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 40, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 187, 255, 255, 255, 255, 154, 49, 54, 195, 255, 255, 255, 255, 217, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 56, 255, 255, 255, 248, 94, 0, 0, 0, 14, 188, 255, 255, 255, 95, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 114, 255, 255, 255, 163, 0, 0, 0, 0, 0, 84, 255, 255, 231, 2, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 108, 255, 255, 255, 163, 0, 0, 0, 0, 0, 194, 255, 255, 131, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 96, 255, 255, 255, 252, 92, 0, 0, 0, 96, 255, 255, 255, 115, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 28, 255, 255, 255, 255, 255, 163, 103, 138, 255, 255, 255, 255, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 159, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 67, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 160, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 27, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 153, 255, 255, 255, 255, 255, 243, 255, 255, 245, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 44, 96, 143, 152, 65, 169, 255, 255, 212, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 206, 255, 255, 207, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 166, 255, 255, 255, 36, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 107, 255, 255, 255, 98, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 47, 255, 255, 255, 136, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 61, 255, 255, 255, 155, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 83, 255, 255, 255, 156, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 47, 255, 255, 255, 134, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 245, 255, 255, 150, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 54, 167, 161, 39, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "))\n",
        "\n",
        "\n",
        "\n",
        "Dumpster_1 = np.array((\n",
        "26, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 26, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 235, 130, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 191, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 187, 235, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 151, 255, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 119, 254, 30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 122, 250, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 105, 254, 26, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 100, 255, 34, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 109, 255, 28, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 124, 255, 40, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 124, 255, 23, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 143, 255, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 149, 255, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 96, 255, 25, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 113, 254, 15, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 136, 255, 23, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 119, 255, 22, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 102, 255, 32, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 83, 253, 49, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 49, 254, 62, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 53, 255, 73, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 248, 140, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 43, 56, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "26, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 26, \n",
        "))\n",
        "Dumpster_3 = np.array((\n",
        "26, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 26, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 75, 157, 231, 255, 255, 255, 203, 105, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 163, 214, 161, 141, 129, 120, 204, 255, 185, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 53, 255, 110, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 176, 207, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 224, 168, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 128, 255, 18, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 103, 255, 99, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 45, 176, 255, 156, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 75, 232, 255, 255, 255, 255, 236, 111, 14, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 96, 206, 140, 79, 79, 143, 236, 255, 255, 83, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 87, 246, 255, 89, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 15, 208, 252, 8, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 255, 157, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 221, 251, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 230, 218, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 255, 135, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 75, 64, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 205, 255, 17, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 95, 255, 24, 0, 0, 0, 0, 0, 0, 0, 0, 183, 255, 69, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 152, 255, 182, 99, 42, 13, 10, 42, 123, 247, 255, 76, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 90, 218, 255, 255, 255, 255, 255, 250, 169, 25, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 24, 67, 94, 98, 55, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "26, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 26, \n",
        "))\n",
        "Dumpster_4 = np.array((\n",
        "26, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 26, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 78, 36, 0, 0, 0, 0, 0, 104, 197, 5, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 254, 206, 0, 0, 0, 0, 0, 148, 255, 43, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 14, 219, 136, 0, 0, 0, 0, 0, 114, 255, 64, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 15, 255, 129, 0, 0, 0, 0, 0, 98, 255, 59, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 255, 188, 0, 0, 0, 0, 0, 115, 251, 14, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 11, 255, 203, 0, 0, 0, 0, 0, 143, 248, 6, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 36, 255, 159, 0, 0, 0, 0, 0, 141, 255, 21, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 50, 255, 134, 0, 0, 0, 0, 0, 154, 252, 18, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 83, 255, 132, 0, 0, 0, 0, 0, 155, 254, 22, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 155, 255, 183, 136, 133, 64, 0, 0, 164, 255, 8, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 58, 255, 255, 255, 255, 255, 255, 229, 74, 172, 251, 1, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 46, 159, 133, 35, 3, 26, 109, 239, 216, 213, 233, 4, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 156, 255, 4, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 170, 240, 1, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 205, 233, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 191, 249, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 201, 248, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 183, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 170, 225, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 155, 224, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 107, 210, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 34, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "26, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 26, \n",
        "))\n",
        "Dumpster_5 = np.array((\n",
        "26, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 26, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 79, 137, 128, 80, 24, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 144, 255, 255, 255, 255, 216, 59, 21, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 73, 255, 255, 255, 255, 255, 255, 255, 227, 30, 1, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 236, 223, 86, 132, 145, 144, 113, 112, 66, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 43, 255, 91, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 139, 246, 28, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 233, 219, 0, 34, 23, 27, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 219, 249, 255, 255, 255, 255, 230, 139, 75, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 29, 237, 255, 218, 191, 183, 151, 255, 255, 255, 139, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 176, 255, 184, 0, 0, 0, 0, 6, 64, 138, 255, 246, 58, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 109, 169, 21, 0, 0, 0, 0, 0, 0, 0, 51, 221, 255, 122, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 204, 255, 87, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 4, 250, 237, 9, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 138, 255, 77, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 62, 255, 126, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 66, 255, 87, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 169, 255, 1, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 61, 255, 149, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 16, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 99, 255, 189, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 33, 175, 118, 0, 0, 0, 0, 0, 0, 20, 82, 207, 255, 164, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 67, 235, 244, 211, 189, 187, 206, 228, 255, 255, 224, 83, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 111, 187, 231, 224, 211, 194, 119, 52, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "26, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 26, \n",
        "))\n",
        "\n",
        "\n",
        "\n",
        "Stencil_2 = np.array((\n",
        "26, 13, 13, 13, 13, 13, 13, 13, 11, 0, 0, 0, 0, 9, 14, 0, 0, 0, 0, 2, 14, 13, 13, 13, 13, 13, 13, 26, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 14, 83, 118, 127, 11, 0, 128, 168, 152, 101, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "13, 0, 0, 0, 0, 0, 0, 7, 179, 246, 255, 255, 255, 56, 0, 248, 255, 255, 255, 224, 38, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 152, 255, 255, 255, 255, 255, 50, 0, 231, 255, 255, 255, 255, 241, 3, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 86, 255, 255, 255, 255, 255, 255, 79, 0, 247, 255, 255, 255, 255, 255, 172, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 188, 255, 255, 255, 255, 249, 222, 48, 2, 181, 230, 255, 255, 255, 255, 250, 4, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 213, 255, 255, 255, 232, 26, 0, 0, 3, 0, 0, 99, 254, 255, 255, 255, 42, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 3, 219, 255, 255, 255, 173, 0, 0, 0, 0, 0, 0, 0, 244, 255, 255, 255, 86, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 8, 80, 86, 64, 54, 9, 0, 0, 0, 0, 0, 0, 77, 255, 255, 255, 255, 59, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 27, 253, 255, 255, 255, 236, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 241, 255, 255, 255, 255, 147, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 220, 255, 255, 255, 255, 224, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 181, 255, 255, 255, 255, 251, 23, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 131, 255, 255, 255, 255, 255, 95, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 47, 255, 255, 255, 255, 255, 163, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 240, 255, 255, 255, 255, 206, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 223, 255, 255, 255, 255, 233, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 73, 255, 255, 255, 255, 236, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 1, 0, 100, 254, 255, 255, 255, 252, 22, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 31, 255, 255, 255, 255, 255, 67, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 243, 255, 255, 255, 255, 148, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 213, 255, 255, 255, 255, 224, 0, 17, 101, 81, 77, 93, 103, 105, 124, 65, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 118, 255, 255, 255, 255, 255, 20, 27, 249, 255, 255, 255, 255, 255, 255, 255, 199, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 178, 255, 255, 255, 255, 144, 0, 237, 255, 255, 255, 255, 255, 255, 255, 255, 193, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 178, 255, 255, 255, 249, 0, 22, 255, 255, 255, 255, 255, 255, 255, 255, 255, 195, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 1, 0, 130, 253, 252, 247, 170, 0, 49, 255, 244, 235, 234, 239, 228, 224, 206, 211, 122, 0, 0, 0, 0, 13, \n",
        "0, 0, 0, 0, 0, 0, 6, 23, 24, 11, 0, 1, 8, 16, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "26, 13, 13, 13, 13, 13, 5, 0, 0, 11, 13, 13, 12, 11, 4, 8, 10, 10, 12, 13, 13, 10, 10, 13, 13, 13, 13, 26, \n",
        "))\n",
        "Stencil_3 = np.array((\n",
        "26, 13, 13, 13, 13, 13, 13, 13, 13, 13, 12, 9, 10, 13, 13, 8, 7, 9, 13, 13, 13, 13, 13, 13, 13, 13, 13, 26, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 1, 140, 198, 226, 177, 0, 16, 210, 231, 224, 142, 0, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 65, 246, 255, 255, 255, 235, 0, 5, 255, 255, 255, 255, 235, 2, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 39, 254, 255, 255, 255, 255, 235, 0, 4, 245, 255, 255, 255, 255, 201, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 2, 214, 255, 255, 255, 255, 255, 221, 0, 2, 220, 254, 255, 255, 255, 255, 120, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 250, 255, 255, 255, 230, 116, 30, 0, 0, 27, 49, 187, 255, 255, 255, 222, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 13, 250, 252, 251, 254, 78, 0, 0, 0, 0, 0, 0, 19, 255, 255, 255, 241, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 12, 63, 32, 33, 40, 0, 0, 0, 0, 0, 0, 0, 63, 255, 255, 255, 247, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 63, 253, 255, 255, 235, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 37, 254, 255, 255, 231, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 38, 54, 68, 85, 198, 255, 255, 255, 171, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 246, 255, 255, 255, 255, 255, 255, 232, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 241, 255, 255, 255, 255, 255, 252, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 253, 255, 255, 255, 255, 255, 248, 186, 18, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 187, 216, 202, 205, 255, 255, 255, 255, 194, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 118, 247, 255, 255, 238, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 66, 249, 255, 255, 243, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 112, 255, 255, 255, 254, 25, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 74, 255, 255, 255, 252, 32, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 37, 176, 196, 217, 193, 0, 0, 0, 0, 0, 0, 0, 47, 255, 255, 255, 241, 5, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 66, 255, 255, 255, 255, 146, 0, 0, 4, 0, 0, 0, 190, 255, 255, 255, 230, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 12, 254, 255, 255, 255, 255, 223, 169, 10, 0, 180, 244, 255, 255, 254, 255, 172, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 205, 255, 255, 255, 255, 255, 234, 2, 0, 220, 255, 255, 255, 255, 239, 22, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 62, 255, 255, 255, 255, 255, 202, 0, 5, 248, 255, 255, 255, 249, 68, 0, 0, 0, 0, 0, 0, 13, \n",
        "13, 0, 0, 0, 0, 0, 0, 91, 226, 255, 255, 255, 206, 0, 8, 247, 255, 245, 189, 16, 0, 0, 0, 0, 0, 0, 0, 13, \n",
        "0, 0, 0, 0, 0, 0, 0, 0, 0, 39, 105, 118, 41, 0, 1, 49, 72, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "26, 13, 13, 13, 13, 13, 13, 13, 5, 0, 0, 0, 0, 13, 13, 0, 0, 0, 11, 13, 13, 13, 13, 13, 13, 13, 13, 26, \n",
        "))\n",
        "Stencil_5 = np.array((\n",
        "4, 6, 5, 4, 5, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 12, 12, 12, 12, 16, \n",
        "7, 0, 0, 0, 0, 0, 122, 188, 186, 190, 183, 171, 139, 187, 186, 194, 182, 198, 206, 205, 207, 35, 0, 0, 0, 0, 0, 3, \n",
        "12, 0, 0, 0, 0, 0, 228, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 98, 0, 0, 0, 0, 0, 2, \n",
        "12, 0, 0, 0, 0, 0, 202, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 79, 0, 0, 0, 0, 0, 2, \n",
        "12, 0, 0, 0, 0, 0, 197, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 91, 0, 0, 0, 0, 0, 2, \n",
        "12, 0, 0, 0, 0, 0, 167, 255, 255, 255, 188, 63, 70, 83, 83, 96, 102, 116, 76, 74, 59, 24, 0, 0, 0, 0, 0, 3, \n",
        "12, 0, 0, 0, 0, 0, 166, 255, 255, 255, 121, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, \n",
        "12, 0, 0, 0, 0, 0, 212, 255, 255, 255, 109, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, \n",
        "12, 0, 0, 0, 0, 0, 219, 255, 255, 255, 100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, \n",
        "12, 0, 0, 0, 0, 0, 213, 255, 255, 255, 122, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, \n",
        "12, 0, 0, 0, 0, 0, 203, 255, 255, 255, 179, 81, 88, 21, 1, 24, 32, 27, 12, 0, 0, 0, 0, 0, 0, 0, 0, 2, \n",
        "12, 0, 0, 0, 0, 0, 205, 255, 255, 255, 255, 255, 255, 70, 1, 176, 255, 255, 251, 196, 41, 0, 0, 0, 0, 0, 0, 2, \n",
        "12, 0, 0, 0, 0, 0, 227, 255, 255, 255, 255, 255, 255, 56, 1, 195, 255, 255, 255, 255, 232, 0, 0, 0, 0, 0, 0, 2, \n",
        "14, 0, 0, 0, 0, 0, 105, 252, 255, 255, 255, 255, 255, 111, 0, 229, 255, 255, 255, 255, 255, 146, 0, 0, 0, 0, 0, 4, \n",
        "13, 0, 0, 0, 0, 0, 0, 57, 222, 223, 223, 226, 230, 76, 0, 185, 252, 255, 255, 255, 255, 255, 18, 0, 0, 0, 0, 5, \n",
        "8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 187, 255, 255, 255, 255, 98, 0, 0, 0, 0, 5, \n",
        "4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 255, 255, 255, 255, 161, 0, 0, 0, 0, 5, \n",
        "6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 226, 255, 255, 255, 163, 0, 0, 0, 0, 5, \n",
        "5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 7, 213, 255, 255, 255, 164, 0, 0, 0, 0, 5, \n",
        "5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6, 205, 255, 255, 255, 182, 0, 0, 0, 0, 5, \n",
        "5, 0, 0, 0, 0, 0, 182, 231, 211, 230, 75, 0, 0, 0, 0, 0, 0, 0, 251, 255, 255, 255, 170, 0, 0, 0, 0, 5, \n",
        "9, 0, 0, 0, 0, 0, 186, 255, 255, 255, 239, 147, 143, 64, 0, 27, 61, 179, 255, 255, 255, 255, 160, 0, 0, 0, 0, 5, \n",
        "10, 0, 0, 0, 0, 0, 62, 255, 255, 255, 255, 255, 255, 173, 0, 144, 255, 255, 255, 255, 255, 255, 101, 0, 0, 0, 0, 5, \n",
        "9, 0, 0, 0, 0, 0, 0, 234, 255, 255, 255, 255, 255, 121, 0, 184, 255, 255, 255, 255, 255, 249, 3, 0, 0, 0, 0, 5, \n",
        "10, 0, 0, 0, 0, 0, 0, 37, 245, 255, 255, 255, 255, 111, 0, 165, 255, 255, 255, 255, 254, 101, 0, 0, 0, 0, 0, 5, \n",
        "6, 0, 0, 0, 0, 0, 0, 0, 30, 149, 189, 224, 224, 79, 0, 91, 228, 233, 224, 146, 57, 0, 0, 0, 0, 0, 0, 5, \n",
        "3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, \n",
        "4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, \n",
        "))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8SE_MNTkzSr",
        "colab_type": "text"
      },
      "source": [
        "### Data pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiqyMzhZd8_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make a list of the digits in each set\n",
        "CoffeeShopDigits_set = np.array(( Coffeeshop_4, Coffeeshop_5, Coffeeshop_6, Coffeeshop_8, ))\n",
        "ConstructionDigits_set = np.array(( Construction_0, Construction_2, Construction_3, Construction_4, Construction_5, Construction_7, Construction_9, ))\n",
        "DumpsterDigits_set = np.array(( Dumpster_1, Dumpster_3, Dumpster_4, Dumpster_5, ))\n",
        "StencilDigits_set = np.array(( Stencil_2, Stencil_3, Stencil_5, ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQXrPSDYfnKJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The targets we want for the images in each set\n",
        "CoffeeShopTargets = ( 4, 5, 6, 8 )\n",
        "ConstructionTargets = ( 0, 2, 3, 4, 5, 7, 9 )\n",
        "DumpsterTargets = ( 1, 3, 4, 5 )\n",
        "StencilTargets = ( 2, 3, 5 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JF-bQqEdoCn",
        "colab_type": "text"
      },
      "source": [
        "As always, we need to pre-process our data. We’ve already got it into\n",
        "a 28 by 28 shape, but that’s not enough. Just like the MNIST data, we\n",
        "need to convert the input pixels into the current Keras floating-point\n",
        "form, and then we must apply the same pre-processing that we\n",
        "applied to the training data we used to train our model. So we’ll use\n",
        "cast_to_floatx() again to get the data into the right type, and then\n",
        "we’ll divide every pixel by 255, just as before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OtbYPmhZsPS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pre-process our data just as we did the MNIST data\n",
        "CoffeeShopDigits_set = keras_backend.cast_to_floatx(CoffeeShopDigits_set)\n",
        "CoffeeShopDigits_set /= 255.0\n",
        "\n",
        "ConstructionDigits_set = keras_backend.cast_to_floatx(ConstructionDigits_set)\n",
        "ConstructionDigits_set /= 255.0\n",
        "\n",
        "DumpsterDigits_set = keras_backend.cast_to_floatx(DumpsterDigits_set)\n",
        "DumpsterDigits_set /= 255.0\n",
        "\n",
        "StencilDigits_set = keras_backend.cast_to_floatx(StencilDigits_set)\n",
        "StencilDigits_set /= 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Dd9K7rSlDIW",
        "colab_type": "text"
      },
      "source": [
        "### Highest-probability predicted class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04sbLs3Lg0N3",
        "colab_type": "text"
      },
      "source": [
        "Now we’re ready to give these images to the model and ask it to identify,\n",
        "or predict, each digit. We’re testing our deep-learning system on\n",
        "new data!\n",
        "\n",
        "There are two types of predictions we can ask for. The simplest one just\n",
        "gives us the highest-probability predicted class for each sample. We\n",
        "get this by calling a method called predict_classes() which is provided\n",
        "by our compiled model. Its first, and only mandatory, argument\n",
        "is the data we want it to predict.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0_PnJlhgIn1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fcb26f85-a365-4997-c57c-e3e53a84ffa1"
      },
      "source": [
        "one_hidden_layer_model.predict_classes(CoffeeShopDigits_set, verbose=0)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 5, 6, 8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPtA5BU6hl-T",
        "colab_type": "text"
      },
      "source": [
        "The result of the prediction is an array of integers, one for each line in\n",
        "the input, telling us what class the system has assigned to that line.\n",
        "\n",
        "Comparing the results, we can see\n",
        "that the system did perfectly! It correctly classified all four digits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbSeY3HshgoM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "93098381-e714-4ad7-8e96-8594d11f3cc6"
      },
      "source": [
        "one_hidden_layer_model.predict_classes(ConstructionDigits_set, verbose=0)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 3, 4, 5, 3, 8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gh0HoeyOmr-J",
        "colab_type": "text"
      },
      "source": [
        "The system got most of the digits right, but misclassified the 4 as a 9,\n",
        "and the 7 as a 3. The 7 seems pretty reasonable, since we could interpret\n",
        "that cross-bar as splitting the figure into an upper and lower curve,\n",
        "sort-of like a 3. Mistaking the 4 for an 9 seems harder to rationalize."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdU8TFGviPax",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a6c4d22f-ab09-4b67-89db-457a9d621637"
      },
      "source": [
        "one_hidden_layer_model.predict_classes(DumpsterDigits_set, verbose=0)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 3, 4, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbmiSEkom3Pe",
        "colab_type": "text"
      },
      "source": [
        "Perfect! Our model’s predictions for the dumpster data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5WXE3aQiQEC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "47007dba-7e2d-49da-f842-53274eee825a"
      },
      "source": [
        "one_hidden_layer_model.predict_classes(StencilDigits_set, verbose=0)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 3, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lD7ZR-NHnAzY",
        "colab_type": "text"
      },
      "source": [
        "Perfect again! The parking-lot data is almost ridiculously unfair. The\n",
        "digits are not hand-drawn, and they all have multiple gaps. This isn’t\n",
        "the sort of thing the model was trained on at all. There’s no reason to\n",
        "think it would interpret these images well. Yet it nailed all three digits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvzrUBWjiftN",
        "colab_type": "text"
      },
      "source": [
        "<img src='https://github.com/rahiakela/img-repo/blob/master/model-prediction-2.JPG?raw=1' width='800'/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAy-TWYolO0R",
        "colab_type": "text"
      },
      "source": [
        "### Prediction probability of each class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzsWSYvRiEoM",
        "colab_type": "text"
      },
      "source": [
        "The other type of prediction we can ask for will give us the probability\n",
        "of each class. This way we can see if there were any close runner-ups,\n",
        "and generally get a feeling for how well the system did at not just a\n",
        "finding the right answer, but discarding the incorrect answers. We get\n",
        "back this list using the predict_proba() method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9uiNhwxiu6y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "129b0511-da6b-4e3b-b7cc-f8126c0ec02d"
      },
      "source": [
        "coffee_probas = one_hidden_layer_model.predict_proba(CoffeeShopDigits_set, verbose=0)\n",
        "coffee_probas[0]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5.7531004e-13, 1.3696770e-10, 3.7612528e-11, 4.9665490e-11,\n",
              "       9.8891068e-01, 1.7268466e-06, 5.9958261e-09, 5.2019145e-06,\n",
              "       5.3311591e-03, 5.7511651e-03], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6jBhPo7jEaN",
        "colab_type": "text"
      },
      "source": [
        "The probabilities for our coffee shop sign’s 4. We first ask\n",
        "for the probabilities for all the images in the set, which gives us back a list\n",
        "of length 4, each element a list of 10 probabilities for that image. Here we\n",
        "print just the first of those lists. The entry at index 4 is the largest, but\n",
        "it’s interesting that the system thought there was a pretty good chance\n",
        "the digit was a 9."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5XgV0H_i4kQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "a3171575-ecf4-4595-a0a5-3878e58470ed"
      },
      "source": [
        "construction_probas = one_hidden_layer_model.predict_proba(ConstructionDigits_set, verbose=0)\n",
        "construction_probas[0]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9.9999976e-01, 1.4787266e-16, 6.9027971e-11, 9.7014675e-16,\n",
              "       2.3598479e-14, 1.9952818e-13, 5.2200215e-12, 1.7427325e-07,\n",
              "       4.9028913e-14, 1.6395784e-07], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqZGg_x5jdAd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "21da1e8c-25cd-49ad-d6a2-1af4c3f2a400"
      },
      "source": [
        "dumpster_probas = one_hidden_layer_model.predict_proba(DumpsterDigits_set, verbose=0)\n",
        "dumpster_probas[0]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.8754685e-08, 9.9989903e-01, 4.2878287e-07, 6.0067188e-05,\n",
              "       1.8501456e-07, 1.8547335e-07, 1.2787474e-06, 1.7732171e-05,\n",
              "       2.0696554e-05, 3.1156293e-07], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehg62-LljeU4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "e791bd88-53b0-4c49-d8b1-17a6e3b58cef"
      },
      "source": [
        "stencil_probas = one_hidden_layer_model.predict_proba(StencilDigits_set, verbose=0)\n",
        "stencil_probas[0]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.8415092e-21, 2.5942375e-08, 9.5571119e-01, 4.4288713e-02,\n",
              "       6.2318451e-33, 7.9175846e-11, 1.2777078e-15, 9.9640828e-18,\n",
              "       4.6574589e-10, 1.4601421e-20], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQvPsFPZlWws",
        "colab_type": "text"
      },
      "source": [
        "### Ploting of probabilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0woTUyrjxKP",
        "colab_type": "text"
      },
      "source": [
        "Let’s plot all the probabilities for the four digits in the coffee shop data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k804OaIKjtq-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "0a0da238-556c-4e94-f190-7f7b3b0376bb"
      },
      "source": [
        "coffee_proba = one_hidden_layer_model.predict_proba(CoffeeShopDigits_set, verbose=0)\n",
        "for i in range(4):\n",
        "    plt.subplot(2, 2, i+1)\n",
        "    plt.bar(range(10), coffee_proba[i], color='#91C0F6', align='center')\n",
        "    plt.xlim(-0.5, 9.5)\n",
        "    plt.ylim(0, 1)\n",
        "    plt.title('4568'[i])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGVCSpCYZUJKkJv0/Aw1aB6VX/hUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8eU6en4j8Iw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "9524e6e2-359b-4104-ed34-d5740a45bc22"
      },
      "source": [
        "construction_proba = one_hidden_layer_model.predict_proba(ConstructionDigits_set, verbose=0)\n",
        "for i in range(4):\n",
        "    plt.subplot(2, 2, i+1)\n",
        "    plt.bar(range(10), construction_proba[i], color='#91C0F6', align='center')\n",
        "    plt.xlim(-0.5, 9.5)\n",
        "    plt.ylim(0, 1)\n",
        "    plt.title('4568'[i])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIGPMXdbkJy6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "bcac92bf-3c58-4224-81fa-3de25ce68c88"
      },
      "source": [
        "dumpster_proba = one_hidden_layer_model.predict_proba(DumpsterDigits_set, verbose=0)\n",
        "for i in range(4):\n",
        "    plt.subplot(2, 2, i+1)\n",
        "    plt.bar(range(10), dumpster_proba[i], color='#91C0F6', align='center')\n",
        "    plt.xlim(-0.5, 9.5)\n",
        "    plt.ylim(0, 1)\n",
        "    plt.title('4568'[i])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncOyQj2JsAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d9ULHZVkM_6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "37328b4f-ad98-4b2f-ab25-2b4ee490fff2"
      },
      "source": [
        "stencil_proba = one_hidden_layer_model.predict_proba(StencilDigits_set, verbose=0)\n",
        "for i in range(3):\n",
        "    plt.subplot(2, 2, i+1)\n",
        "    plt.bar(range(10), stencil_proba[i], color='#91C0F6', align='center')\n",
        "    plt.xlim(-0.5, 9.5)\n",
        "    plt.ylim(0, 1)\n",
        "    plt.title('4568'[i])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhfk_kqunI_4",
        "colab_type": "text"
      },
      "source": [
        "Our tiny model with just two layers, and just 20 epochs of training, did\n",
        "a great job, correctly classifying 16 out of 18 of our images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjsbCBISnKD-",
        "colab_type": "text"
      },
      "source": [
        "## Analysis of Training History"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UedrEoLWka43",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}