{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5-training-history-analysis.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/deep-learning--from-basics-to-practice/blob/23-keras-part-1/5_training_history_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEkrx1DZwrbV",
        "colab_type": "text"
      },
      "source": [
        "#Analysis of Training History"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DoHUx4vyJQ2",
        "colab_type": "text"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLfz9j5ryKpk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "outputId": "3ca89441-db2c-4b43-e862-7bcc7a8a50b5"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras import backend as Keras_backend\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from keras import backend as keras_backend\n",
        "keras_backend.set_image_data_format('channels_last')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvpPm4npyQhS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "8e54051e-ba46-41f1-ad6d-da9ea48edcff"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras import backend as keras_backend\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# load MNIST data and save sizes\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "image_height = X_train.shape[1]\n",
        "image_width = X_train.shape[2]\n",
        "number_of_pixels = image_height * image_width\n",
        "\n",
        "\n",
        "# convert to floating-point\n",
        "X_train = keras_backend.cast_to_floatx(X_train)\n",
        "X_test = keras_backend.cast_to_floatx(X_test)\n",
        "\n",
        "\n",
        "# scale data to range [0, 1]\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "\n",
        "\n",
        "# save the original y_train and y_test\n",
        "original_y_train = y_train\n",
        "original_y_test = y_test\n",
        "\n",
        "# replace label data with one-hot encoded versions\n",
        "number_of_classes = 1 + max(np.append(y_train, y_test)).astype(np.int32)\n",
        "\n",
        "# encode each list into one-hot arrays of the size we just found\n",
        "y_train = to_categorical(y_train, num_classes=number_of_classes)\n",
        "y_test = to_categorical(y_test, num_classes=number_of_classes)\n",
        "\n",
        "# reshape samples to 2D grid, one line per image\n",
        "X_train = X_train.reshape([X_train.shape[0], number_of_pixels])\n",
        "X_test = X_test.reshape([X_test.shape[0], number_of_pixels])\n",
        "\n",
        "def make_one_hidden_layer_model():\n",
        "\n",
        "  # create an empty model\n",
        "  model = Sequential()\n",
        "\n",
        "  # add a fully-connected hidden layer with #nodes = #pixels\n",
        "  model.add(Dense(number_of_pixels, activation='relu', input_shape=[number_of_pixels]))\n",
        "\n",
        "  # add an output layer with softmax activation\n",
        "  model.add(Dense(number_of_classes, activation='softmax'))\n",
        "\n",
        "  # compile the model to turn it from specification to code\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "# make the model\n",
        "one_hidden_layer_model = make_one_hidden_layer_model()  \n",
        "one_hidden_layer_model.summary()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 784)               615440    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                7850      \n",
            "=================================================================\n",
            "Total params: 623,290\n",
            "Trainable params: 623,290\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vQApmTfx51O",
        "colab_type": "text"
      },
      "source": [
        "### Motivation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiBiMSfRx8cm",
        "colab_type": "text"
      },
      "source": [
        "We mentioned before that fit() returned some history information\n",
        "that tells us how the training went. Let’s investigate that now and see\n",
        "what we can learn.\n",
        "\n",
        "To gather lots of data, this time we’ll train for 100 epochs, even though\n",
        "we know the system hits 100% on the training data after just 20 epochs.\n",
        "\n",
        "The history information is returned by fit(), so we can just assign the\n",
        "output of that method to a variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qxWVBe5yDnA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e7fd2c34-0086-4185-d0f9-9a5519adb0a2"
      },
      "source": [
        "# call fit() to train the model, and save the history\n",
        "one_hidden_layer_history = one_hidden_layer_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=256, verbose=2)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            " - 6s - loss: 0.3040 - acc: 0.9135 - val_loss: 0.1523 - val_acc: 0.9547\n",
            "Epoch 2/100\n",
            " - 5s - loss: 0.1226 - acc: 0.9651 - val_loss: 0.1052 - val_acc: 0.9687\n",
            "Epoch 3/100\n",
            " - 5s - loss: 0.0796 - acc: 0.9766 - val_loss: 0.0930 - val_acc: 0.9716\n",
            "Epoch 4/100\n",
            " - 5s - loss: 0.0569 - acc: 0.9838 - val_loss: 0.0700 - val_acc: 0.9795\n",
            "Epoch 5/100\n",
            " - 5s - loss: 0.0415 - acc: 0.9883 - val_loss: 0.0632 - val_acc: 0.9807\n",
            "Epoch 6/100\n",
            " - 5s - loss: 0.0317 - acc: 0.9912 - val_loss: 0.0601 - val_acc: 0.9811\n",
            "Epoch 7/100\n",
            " - 5s - loss: 0.0234 - acc: 0.9939 - val_loss: 0.0617 - val_acc: 0.9799\n",
            "Epoch 8/100\n",
            " - 5s - loss: 0.0180 - acc: 0.9960 - val_loss: 0.0646 - val_acc: 0.9804\n",
            "Epoch 9/100\n",
            " - 5s - loss: 0.0138 - acc: 0.9971 - val_loss: 0.0569 - val_acc: 0.9819\n",
            "Epoch 10/100\n",
            " - 5s - loss: 0.0106 - acc: 0.9980 - val_loss: 0.0582 - val_acc: 0.9823\n",
            "Epoch 11/100\n",
            " - 5s - loss: 0.0078 - acc: 0.9988 - val_loss: 0.0592 - val_acc: 0.9827\n",
            "Epoch 12/100\n",
            " - 5s - loss: 0.0059 - acc: 0.9992 - val_loss: 0.0604 - val_acc: 0.9814\n",
            "Epoch 13/100\n",
            " - 5s - loss: 0.0043 - acc: 0.9996 - val_loss: 0.0597 - val_acc: 0.9828\n",
            "Epoch 14/100\n",
            " - 5s - loss: 0.0034 - acc: 0.9997 - val_loss: 0.0644 - val_acc: 0.9815\n",
            "Epoch 15/100\n",
            " - 5s - loss: 0.0048 - acc: 0.9991 - val_loss: 0.0611 - val_acc: 0.9823\n",
            "Epoch 16/100\n",
            " - 5s - loss: 0.0064 - acc: 0.9986 - val_loss: 0.0809 - val_acc: 0.9787\n",
            "Epoch 17/100\n",
            " - 5s - loss: 0.0058 - acc: 0.9988 - val_loss: 0.0635 - val_acc: 0.9826\n",
            "Epoch 18/100\n",
            " - 5s - loss: 0.0020 - acc: 0.9999 - val_loss: 0.0631 - val_acc: 0.9834\n",
            "Epoch 19/100\n",
            " - 5s - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0665 - val_acc: 0.9828\n",
            "Epoch 20/100\n",
            " - 5s - loss: 9.4437e-04 - acc: 1.0000 - val_loss: 0.0660 - val_acc: 0.9828\n",
            "Epoch 21/100\n",
            " - 5s - loss: 6.7724e-04 - acc: 1.0000 - val_loss: 0.0633 - val_acc: 0.9835\n",
            "Epoch 22/100\n",
            " - 5s - loss: 4.8250e-04 - acc: 1.0000 - val_loss: 0.0645 - val_acc: 0.9840\n",
            "Epoch 23/100\n",
            " - 5s - loss: 4.1322e-04 - acc: 1.0000 - val_loss: 0.0638 - val_acc: 0.9842\n",
            "Epoch 24/100\n",
            " - 5s - loss: 3.4598e-04 - acc: 1.0000 - val_loss: 0.0659 - val_acc: 0.9838\n",
            "Epoch 25/100\n",
            " - 5s - loss: 3.0571e-04 - acc: 1.0000 - val_loss: 0.0665 - val_acc: 0.9835\n",
            "Epoch 26/100\n",
            " - 5s - loss: 2.6935e-04 - acc: 1.0000 - val_loss: 0.0674 - val_acc: 0.9836\n",
            "Epoch 27/100\n",
            " - 5s - loss: 2.4314e-04 - acc: 1.0000 - val_loss: 0.0668 - val_acc: 0.9841\n",
            "Epoch 28/100\n",
            " - 5s - loss: 2.1955e-04 - acc: 1.0000 - val_loss: 0.0675 - val_acc: 0.9843\n",
            "Epoch 29/100\n",
            " - 5s - loss: 1.9219e-04 - acc: 1.0000 - val_loss: 0.0677 - val_acc: 0.9843\n",
            "Epoch 30/100\n",
            " - 5s - loss: 1.7353e-04 - acc: 1.0000 - val_loss: 0.0689 - val_acc: 0.9841\n",
            "Epoch 31/100\n",
            " - 5s - loss: 1.5687e-04 - acc: 1.0000 - val_loss: 0.0690 - val_acc: 0.9839\n",
            "Epoch 32/100\n",
            " - 5s - loss: 1.4524e-04 - acc: 1.0000 - val_loss: 0.0689 - val_acc: 0.9842\n",
            "Epoch 33/100\n",
            " - 5s - loss: 1.2711e-04 - acc: 1.0000 - val_loss: 0.0707 - val_acc: 0.9841\n",
            "Epoch 34/100\n",
            " - 5s - loss: 1.0574e-04 - acc: 1.0000 - val_loss: 0.0714 - val_acc: 0.9845\n",
            "Epoch 35/100\n",
            " - 5s - loss: 9.5190e-05 - acc: 1.0000 - val_loss: 0.0716 - val_acc: 0.9842\n",
            "Epoch 36/100\n",
            " - 5s - loss: 8.5759e-05 - acc: 1.0000 - val_loss: 0.0729 - val_acc: 0.9837\n",
            "Epoch 37/100\n",
            " - 5s - loss: 7.4015e-05 - acc: 1.0000 - val_loss: 0.0744 - val_acc: 0.9836\n",
            "Epoch 38/100\n",
            " - 5s - loss: 6.5992e-05 - acc: 1.0000 - val_loss: 0.0737 - val_acc: 0.9840\n",
            "Epoch 39/100\n",
            " - 5s - loss: 5.8951e-05 - acc: 1.0000 - val_loss: 0.0739 - val_acc: 0.9838\n",
            "Epoch 40/100\n",
            " - 5s - loss: 0.0230 - acc: 0.9936 - val_loss: 0.1045 - val_acc: 0.9747\n",
            "Epoch 41/100\n",
            " - 5s - loss: 0.0171 - acc: 0.9943 - val_loss: 0.0718 - val_acc: 0.9824\n",
            "Epoch 42/100\n",
            " - 5s - loss: 0.0032 - acc: 0.9991 - val_loss: 0.0730 - val_acc: 0.9826\n",
            "Epoch 43/100\n",
            " - 5s - loss: 8.0955e-04 - acc: 0.9999 - val_loss: 0.0682 - val_acc: 0.9836\n",
            "Epoch 44/100\n",
            " - 5s - loss: 3.3924e-04 - acc: 1.0000 - val_loss: 0.0701 - val_acc: 0.9849\n",
            "Epoch 45/100\n",
            " - 5s - loss: 4.0661e-04 - acc: 1.0000 - val_loss: 0.0687 - val_acc: 0.9845\n",
            "Epoch 46/100\n",
            " - 5s - loss: 2.0815e-04 - acc: 1.0000 - val_loss: 0.0690 - val_acc: 0.9846\n",
            "Epoch 47/100\n",
            " - 5s - loss: 1.6477e-04 - acc: 1.0000 - val_loss: 0.0693 - val_acc: 0.9846\n",
            "Epoch 48/100\n",
            " - 5s - loss: 1.4509e-04 - acc: 1.0000 - val_loss: 0.0696 - val_acc: 0.9845\n",
            "Epoch 49/100\n",
            " - 5s - loss: 1.2759e-04 - acc: 1.0000 - val_loss: 0.0698 - val_acc: 0.9845\n",
            "Epoch 50/100\n",
            " - 5s - loss: 1.1469e-04 - acc: 1.0000 - val_loss: 0.0703 - val_acc: 0.9846\n",
            "Epoch 51/100\n",
            " - 5s - loss: 1.0338e-04 - acc: 1.0000 - val_loss: 0.0710 - val_acc: 0.9847\n",
            "Epoch 52/100\n",
            " - 5s - loss: 9.3381e-05 - acc: 1.0000 - val_loss: 0.0712 - val_acc: 0.9848\n",
            "Epoch 53/100\n",
            " - 5s - loss: 8.4420e-05 - acc: 1.0000 - val_loss: 0.0717 - val_acc: 0.9848\n",
            "Epoch 54/100\n",
            " - 5s - loss: 7.6966e-05 - acc: 1.0000 - val_loss: 0.0723 - val_acc: 0.9849\n",
            "Epoch 55/100\n",
            " - 5s - loss: 7.0174e-05 - acc: 1.0000 - val_loss: 0.0724 - val_acc: 0.9853\n",
            "Epoch 56/100\n",
            " - 5s - loss: 6.3882e-05 - acc: 1.0000 - val_loss: 0.0722 - val_acc: 0.9853\n",
            "Epoch 57/100\n",
            " - 5s - loss: 5.9188e-05 - acc: 1.0000 - val_loss: 0.0729 - val_acc: 0.9848\n",
            "Epoch 58/100\n",
            " - 5s - loss: 5.3013e-05 - acc: 1.0000 - val_loss: 0.0732 - val_acc: 0.9847\n",
            "Epoch 59/100\n",
            " - 5s - loss: 4.8745e-05 - acc: 1.0000 - val_loss: 0.0736 - val_acc: 0.9848\n",
            "Epoch 60/100\n",
            " - 5s - loss: 4.4404e-05 - acc: 1.0000 - val_loss: 0.0740 - val_acc: 0.9848\n",
            "Epoch 61/100\n",
            " - 5s - loss: 4.0135e-05 - acc: 1.0000 - val_loss: 0.0736 - val_acc: 0.9852\n",
            "Epoch 62/100\n",
            " - 5s - loss: 3.6705e-05 - acc: 1.0000 - val_loss: 0.0745 - val_acc: 0.9846\n",
            "Epoch 63/100\n",
            " - 5s - loss: 3.3628e-05 - acc: 1.0000 - val_loss: 0.0750 - val_acc: 0.9850\n",
            "Epoch 64/100\n",
            " - 5s - loss: 3.0332e-05 - acc: 1.0000 - val_loss: 0.0754 - val_acc: 0.9850\n",
            "Epoch 65/100\n",
            " - 5s - loss: 2.7771e-05 - acc: 1.0000 - val_loss: 0.0759 - val_acc: 0.9850\n",
            "Epoch 66/100\n",
            " - 5s - loss: 2.4996e-05 - acc: 1.0000 - val_loss: 0.0760 - val_acc: 0.9852\n",
            "Epoch 67/100\n",
            " - 5s - loss: 2.2379e-05 - acc: 1.0000 - val_loss: 0.0770 - val_acc: 0.9850\n",
            "Epoch 68/100\n",
            " - 5s - loss: 2.0512e-05 - acc: 1.0000 - val_loss: 0.0773 - val_acc: 0.9850\n",
            "Epoch 69/100\n",
            " - 5s - loss: 1.8264e-05 - acc: 1.0000 - val_loss: 0.0774 - val_acc: 0.9850\n",
            "Epoch 70/100\n",
            " - 5s - loss: 1.6273e-05 - acc: 1.0000 - val_loss: 0.0776 - val_acc: 0.9849\n",
            "Epoch 71/100\n",
            " - 5s - loss: 1.4809e-05 - acc: 1.0000 - val_loss: 0.0789 - val_acc: 0.9850\n",
            "Epoch 72/100\n",
            " - 5s - loss: 1.3491e-05 - acc: 1.0000 - val_loss: 0.0789 - val_acc: 0.9853\n",
            "Epoch 73/100\n",
            " - 5s - loss: 1.1954e-05 - acc: 1.0000 - val_loss: 0.0793 - val_acc: 0.9854\n",
            "Epoch 74/100\n",
            " - 5s - loss: 1.0759e-05 - acc: 1.0000 - val_loss: 0.0794 - val_acc: 0.9851\n",
            "Epoch 75/100\n",
            " - 5s - loss: 9.5353e-06 - acc: 1.0000 - val_loss: 0.0806 - val_acc: 0.9849\n",
            "Epoch 76/100\n",
            " - 5s - loss: 8.7417e-06 - acc: 1.0000 - val_loss: 0.0807 - val_acc: 0.9851\n",
            "Epoch 77/100\n",
            " - 5s - loss: 7.7317e-06 - acc: 1.0000 - val_loss: 0.0817 - val_acc: 0.9851\n",
            "Epoch 78/100\n",
            " - 5s - loss: 7.1805e-06 - acc: 1.0000 - val_loss: 0.0809 - val_acc: 0.9852\n",
            "Epoch 79/100\n",
            " - 5s - loss: 6.2688e-06 - acc: 1.0000 - val_loss: 0.0820 - val_acc: 0.9849\n",
            "Epoch 80/100\n",
            " - 5s - loss: 5.6770e-06 - acc: 1.0000 - val_loss: 0.0826 - val_acc: 0.9851\n",
            "Epoch 81/100\n",
            " - 5s - loss: 4.9969e-06 - acc: 1.0000 - val_loss: 0.0831 - val_acc: 0.9850\n",
            "Epoch 82/100\n",
            " - 5s - loss: 4.4671e-06 - acc: 1.0000 - val_loss: 0.0833 - val_acc: 0.9849\n",
            "Epoch 83/100\n",
            " - 5s - loss: 4.0705e-06 - acc: 1.0000 - val_loss: 0.0845 - val_acc: 0.9849\n",
            "Epoch 84/100\n",
            " - 5s - loss: 3.5824e-06 - acc: 1.0000 - val_loss: 0.0843 - val_acc: 0.9853\n",
            "Epoch 85/100\n",
            " - 5s - loss: 3.2518e-06 - acc: 1.0000 - val_loss: 0.0851 - val_acc: 0.9850\n",
            "Epoch 86/100\n",
            " - 5s - loss: 2.8897e-06 - acc: 1.0000 - val_loss: 0.0858 - val_acc: 0.9847\n",
            "Epoch 87/100\n",
            " - 5s - loss: 2.6293e-06 - acc: 1.0000 - val_loss: 0.0859 - val_acc: 0.9850\n",
            "Epoch 88/100\n",
            " - 5s - loss: 2.3265e-06 - acc: 1.0000 - val_loss: 0.0857 - val_acc: 0.9852\n",
            "Epoch 89/100\n",
            " - 5s - loss: 2.0929e-06 - acc: 1.0000 - val_loss: 0.0869 - val_acc: 0.9849\n",
            "Epoch 90/100\n",
            " - 5s - loss: 1.8954e-06 - acc: 1.0000 - val_loss: 0.0868 - val_acc: 0.9847\n",
            "Epoch 91/100\n",
            " - 5s - loss: 1.6921e-06 - acc: 1.0000 - val_loss: 0.0884 - val_acc: 0.9849\n",
            "Epoch 92/100\n",
            " - 5s - loss: 1.5186e-06 - acc: 1.0000 - val_loss: 0.0884 - val_acc: 0.9850\n",
            "Epoch 93/100\n",
            " - 5s - loss: 1.4774e-06 - acc: 1.0000 - val_loss: 0.0888 - val_acc: 0.9851\n",
            "Epoch 94/100\n",
            " - 5s - loss: 1.2615e-06 - acc: 1.0000 - val_loss: 0.0894 - val_acc: 0.9847\n",
            "Epoch 95/100\n",
            " - 5s - loss: 1.1131e-06 - acc: 1.0000 - val_loss: 0.0896 - val_acc: 0.9850\n",
            "Epoch 96/100\n",
            " - 5s - loss: 1.0154e-06 - acc: 1.0000 - val_loss: 0.0903 - val_acc: 0.9849\n",
            "Epoch 97/100\n",
            " - 5s - loss: 9.1503e-07 - acc: 1.0000 - val_loss: 0.0917 - val_acc: 0.9850\n",
            "Epoch 98/100\n",
            " - 5s - loss: 8.4317e-07 - acc: 1.0000 - val_loss: 0.0915 - val_acc: 0.9851\n",
            "Epoch 99/100\n",
            " - 5s - loss: 7.9592e-07 - acc: 1.0000 - val_loss: 0.0912 - val_acc: 0.9849\n",
            "Epoch 100/100\n",
            " - 5s - loss: 6.9817e-07 - acc: 1.0000 - val_loss: 0.0920 - val_acc: 0.9851\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75K_CqOWyhv_",
        "colab_type": "text"
      },
      "source": [
        "This contains a bunch of fields that\n",
        "summarize the training process (like how many epochs it ran for, and\n",
        "what parameters we used). The field that’s most interesting to us right\n",
        "now is called history. It’s a Python dictionary object that contains the\n",
        "accuracy and loss values for both the training and validation sets after\n",
        "each epoch.\n",
        "\n",
        "The training accuracies are in this dictionary as a list stored under the\n",
        "key ′acc′, so we’d get them from one_hidden_layer_history with\n",
        "one_hidden_layer_history.history[′acc′] (that’s a lot of typing!).\n",
        "The training loss uses the key ′loss′. Similarly, the validation accuracy\n",
        "and loss are stored with the keys ′val_acc′ and ′val_loss′.\n",
        "\n",
        "Plots the accuracy and loss of our training data graphically."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgXrxqaVy4UR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "9b76cb41-9b14-42f5-d756-ad7765f7c0b7"
      },
      "source": [
        "history = one_hidden_layer_history  # a copy with a shorter name\n",
        "xs = range(len(history.history['acc']))\n",
        "\n",
        "plt.figure(figsize=(10,3))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(xs, history.history['acc'], label='train')\n",
        "plt.plot(xs, history.history['val_acc'], label='validation')\n",
        "plt.legend(loc='lower right')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('one hidden layer accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(xs, history.history['loss'], label='train')\n",
        "plt.plot(xs, history.history['val_loss'], label='validation')\n",
        "plt.legend(loc='upper right')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.title('one hidden layer loss')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAADgCAYAAABGmMFYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x216 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8jNRmGozLZp",
        "colab_type": "text"
      },
      "source": [
        "First, it’s worth noting the scales of the data. The accuracy graph begins\n",
        "at about 0.91 (and tops out at 1.0). That means that after just one epoch\n",
        "of training, our system was up to 91% accuracy. That’s far from perfect,\n",
        "but it’s pretty amazing for such a tiny network and one epoch of training.\n",
        "The loss plot has a correspondingly small range, from 0 to just 0.3.\n",
        "\n",
        "Both graphs show some spikes. This is probably due to a time when the\n",
        "samples arrived in just the right order so that some systematic errors\n",
        "were able to accumulate. The system righted itself nearly immediately\n",
        "in both cases.\n",
        "\n",
        "The training loss quickly drops to 0 by about the 20th epoch, and except\n",
        "for the spikes, it stays there. But the validation loss is slowly increasing.\n",
        "In other words, **the training loss and validation loss are diverging.\n",
        "This is a picture of overfitting.**\n",
        "\n",
        "Learning during overfitting is actually reducing our performance on\n",
        "the validation data, as the system fruitlessly learns more and more\n",
        "about the training set, sharpening its rules and memorizing details.\n",
        "This is a complete waste of effort, and it comes at the expense of losing\n",
        "generality, with each epoch causing even more harm to the network’s accuracy on new data. Though it doesn’t look like the accuracy is dropping\n",
        "in these graphs, the increasing validation loss suggests that that\n",
        "time may come, if we kept on training.\n",
        "\n",
        "To prevent this overfitting, we might be tempted to stop training where\n",
        "the loss or accuracy curves cross one another, but this would be too\n",
        "early. The validation accuracy is still improving, and the validation\n",
        "loss is still generally dropping. The best place to stop would be when\n",
        "our validation loss or accuracy stop improving. That is, when the loss\n",
        "starts to increase or the accuracy starts to drop. Of these two choices,\n",
        "we usually use increasing loss on the validation set as our trigger to\n",
        "stop training.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ib41j0m0BZL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "dcd42025-bd46-4784-a3c9-8a0caf17163e"
      },
      "source": [
        "# What's inside the history?\n",
        "dir(one_hidden_layer_history)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " 'epoch',\n",
              " 'history',\n",
              " 'model',\n",
              " 'on_batch_begin',\n",
              " 'on_batch_end',\n",
              " 'on_epoch_begin',\n",
              " 'on_epoch_end',\n",
              " 'on_predict_batch_begin',\n",
              " 'on_predict_batch_end',\n",
              " 'on_predict_begin',\n",
              " 'on_predict_end',\n",
              " 'on_test_batch_begin',\n",
              " 'on_test_batch_end',\n",
              " 'on_test_begin',\n",
              " 'on_test_end',\n",
              " 'on_train_batch_begin',\n",
              " 'on_train_batch_end',\n",
              " 'on_train_begin',\n",
              " 'on_train_end',\n",
              " 'params',\n",
              " 'set_model',\n",
              " 'set_params',\n",
              " 'validation_data']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H197ml50Fbj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "dc4946e0-2356-437e-dee7-00edf0601e22"
      },
      "source": [
        "# What's inside the 'history' field?\n",
        "dir(one_hidden_layer_history.history)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__class__',\n",
              " '__contains__',\n",
              " '__delattr__',\n",
              " '__delitem__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getitem__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__iter__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__lt__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__setitem__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " 'clear',\n",
              " 'copy',\n",
              " 'fromkeys',\n",
              " 'get',\n",
              " 'items',\n",
              " 'keys',\n",
              " 'pop',\n",
              " 'popitem',\n",
              " 'setdefault',\n",
              " 'update',\n",
              " 'values']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhdC3PdR0-QM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}